{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from convert import images_to_video\n",
    "from convert import state_list_to_image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% import\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "map_filepath = '../image/map.png'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "class MyAction:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def sample(self):\n",
    "        return random.randint(0, self.n - 1)\n",
    "\n",
    "\n",
    "class MyObservation:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "\n",
    "class MyEnv:\n",
    "    def __init__(self, map):\n",
    "        # 上下左右\n",
    "        self.action_space = MyAction(4)\n",
    "        self.map = map\n",
    "        # [0, 1, 2, ..., 49]\n",
    "        # [50, 51, 52, ..., 99]\n",
    "        self.observation_space = MyObservation(map.shape[0]*map.shape[1])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.current_state = [22, 36]\n",
    "        self.init_state = self.current_state[0] * 50 + self.current_state[1]\n",
    "        self.reward_table = np.zeros(self.map.shape)\n",
    "        for i in range(map.shape[0]):\n",
    "            for j in range(map.shape[1]):\n",
    "                self.reward_table[i,j] = self.map[i,j]\n",
    "        for i in range(map.shape[0]):\n",
    "            for j in range(map.shape[1]):\n",
    "                if self.reward_table[i, j] != 255:\n",
    "                    self.reward_table[i, j] = -64\n",
    "                    continue\n",
    "                if (i < 22) or (i > 32):\n",
    "                    self.reward_table[i,j] = 128\n",
    "                elif j < 26:\n",
    "                    self.reward_table[i,j] = 128\n",
    "        self.reward_table[self.current_state[0], self.current_state[1]] = 0\n",
    "        self.current_reward = 0\n",
    "        self.done = False\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        if action == 0: # 上\n",
    "            self.current_state[0] -= 1\n",
    "        if action == 1: # 下\n",
    "            self.current_state[0] += 1\n",
    "        if action == 2: # 左\n",
    "            self.current_state[1] -= 1\n",
    "        if action == 3: # 右\n",
    "            self.current_state[1] += 1\n",
    "        if self.current_state[0] < 0:\n",
    "            self.current_state[0] = 0\n",
    "            self.done = True\n",
    "        if self.current_state[0] >= map.shape[0]:\n",
    "            self.current_state[0] = map.shape[0]-1\n",
    "            self.done = True\n",
    "        if self.current_state[1] < 0:\n",
    "            self.current_state[1] = 0\n",
    "            self.done = True\n",
    "        if self.current_state[1] >= map.shape[1]:\n",
    "            self.current_state[1] = map.shape[1]-1\n",
    "            self.done = True\n",
    "        self.current_reward = self.reward_table[self.current_state[0], self.current_state[1]]\n",
    "\n",
    "        if self.reward_table[self.current_state[0], self.current_state[1]] > 1:\n",
    "            self.reward_table[self.current_state[0], self.current_state[1]] /= 2\n",
    "        if self.current_step > 34:\n",
    "            self.done = True\n",
    "        next_state = self.current_state[0] * 50 + self.current_state[1]\n",
    "        reward = self.current_reward\n",
    "        done = self.done\n",
    "        info = None\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "\n",
    "map = 255 - np.array(Image.open(map_filepath).convert('L'))\n",
    "env = MyEnv(map)\n",
    "print(map[13, 26])\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "actions = env.action_space.n\n",
    "states = env.observation_space.n\n",
    "eposides = 5000000\n",
    "save_interval = 10000\n",
    "min_epsilon = 0.1\n",
    "max_epsilon = 0.9\n",
    "epsilon = 0.2\n",
    "gamma = 0.9\n",
    "alpha = 0.01\n",
    "filename = 'rewards_%s_%s_%s_%s.csv' %(eposides, epsilon, gamma, alpha)\n",
    "outputDir = '../output/'\n",
    "\n",
    "\n",
    "\n",
    "# Create Q table with all rewards = 0\n",
    "q_table = np.zeros((states, actions))\n",
    "#q_table = np.load('q_table_20200629_20')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def save_q_table(epoch):\n",
    "    np.save(outputDir+'q_table_{}'.format(epoch), q_table)\n",
    "\n",
    "def run_test(epoch):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    test_state = env.init_state\n",
    "    state_list = []\n",
    "    test_steps = 0\n",
    "    test_total_reward = 0\n",
    "    while not done:\n",
    "        state_list.append(test_state)\n",
    "        action = np.argmax(q_table[test_state,:])\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        test_state = next_state\n",
    "        test_steps = test_steps + 1\n",
    "        test_total_reward = test_total_reward + reward\n",
    "    with open(outputDir+'state_list_{}_{:.0f}_{}.csv'.format(epoch, test_total_reward, test_steps), 'w') as output_state_list:\n",
    "        output_csv = csv.writer(output_state_list)\n",
    "        output_csv.writerow(state_list)\n",
    "    state_list_to_image.state_list_to_image(epoch, test_total_reward, test_steps, map_filepath, '../output')\n",
    "    images_to_video.images_to_video(epoch, test_total_reward, test_steps, 10, (640, 640), '../output')\n",
    "    print('Test Epoch {}, Total reward {:.0f}, steps {}'.format(epoch, test_total_reward, test_steps))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch 1, Total reward -1152, steps 35\n",
      "Episode 10000, avg_s 34.998, avg_tot_r -1044.364, max_tot_r 4110.500, elapsed 25.161 s, epsilon=0.90\n",
      "Test Epoch 10000, Total reward 1797, steps 35\n",
      "Episode 20000, avg_s 34.999, avg_tot_r -984.351, max_tot_r 3680.062, elapsed 24.651 s, epsilon=0.90\n",
      "Test Epoch 20000, Total reward 2051, steps 35\n",
      "Episode 30000, avg_s 34.998, avg_tot_r -954.362, max_tot_r 3774.938, elapsed 25.286 s, epsilon=0.90\n",
      "Test Epoch 30000, Total reward 2305, steps 35\n",
      "Episode 40000, avg_s 34.999, avg_tot_r -949.473, max_tot_r 3503.500, elapsed 25.579 s, epsilon=0.89\n",
      "Test Epoch 40000, Total reward 2305, steps 35\n",
      "Episode 50000, avg_s 34.999, avg_tot_r -938.149, max_tot_r 3711.438, elapsed 27.167 s, epsilon=0.89\n",
      "Test Epoch 50000, Total reward 2305, steps 35\n",
      "Episode 60000, avg_s 35.000, avg_tot_r -898.324, max_tot_r 3918.375, elapsed 27.125 s, epsilon=0.89\n",
      "Test Epoch 60000, Total reward 2559, steps 35\n",
      "Episode 70000, avg_s 34.999, avg_tot_r -900.794, max_tot_r 3630.750, elapsed 26.878 s, epsilon=0.89\n",
      "Test Epoch 70000, Total reward 2559, steps 35\n",
      "Episode 80000, avg_s 35.000, avg_tot_r -901.032, max_tot_r 3950.250, elapsed 26.935 s, epsilon=0.89\n",
      "Test Epoch 80000, Total reward 2559, steps 35\n",
      "Episode 90000, avg_s 35.000, avg_tot_r -877.506, max_tot_r 3761.000, elapsed 26.966 s, epsilon=0.89\n",
      "Test Epoch 90000, Total reward 2813, steps 35\n",
      "Episode 100000, avg_s 35.000, avg_tot_r -872.166, max_tot_r 4031.938, elapsed 41.692 s, epsilon=0.88\n",
      "Test Epoch 100000, Total reward 2813, steps 35\n",
      "Episode 110000, avg_s 35.000, avg_tot_r -865.490, max_tot_r 4301.625, elapsed 27.139 s, epsilon=0.88\n",
      "Test Epoch 110000, Total reward 2813, steps 35\n",
      "Episode 120000, avg_s 34.999, avg_tot_r -859.386, max_tot_r 3919.875, elapsed 27.439 s, epsilon=0.88\n",
      "Test Epoch 120000, Total reward 2813, steps 35\n",
      "Episode 130000, avg_s 34.999, avg_tot_r -843.008, max_tot_r 3822.000, elapsed 27.152 s, epsilon=0.88\n",
      "Test Epoch 130000, Total reward 3067, steps 35\n",
      "Episode 140000, avg_s 35.000, avg_tot_r -818.081, max_tot_r 4176.000, elapsed 30.126 s, epsilon=0.88\n",
      "Test Epoch 140000, Total reward 2813, steps 35\n",
      "Episode 150000, avg_s 34.999, avg_tot_r -810.609, max_tot_r 3983.625, elapsed 28.268 s, epsilon=0.88\n",
      "Test Epoch 150000, Total reward 3067, steps 35\n",
      "Episode 160000, avg_s 35.000, avg_tot_r -792.286, max_tot_r 4525.750, elapsed 27.638 s, epsilon=0.87\n",
      "Test Epoch 160000, Total reward 3067, steps 35\n",
      "Episode 170000, avg_s 34.998, avg_tot_r -787.440, max_tot_r 4239.375, elapsed 28.416 s, epsilon=0.87\n",
      "Test Epoch 170000, Total reward 2813, steps 35\n",
      "Episode 180000, avg_s 35.000, avg_tot_r -770.073, max_tot_r 3982.125, elapsed 28.442 s, epsilon=0.87\n",
      "Test Epoch 180000, Total reward 3321, steps 35\n",
      "Episode 190000, avg_s 35.000, avg_tot_r -744.238, max_tot_r 3968.562, elapsed 27.247 s, epsilon=0.87\n",
      "Test Epoch 190000, Total reward 3321, steps 35\n",
      "Episode 200000, avg_s 35.000, avg_tot_r -751.561, max_tot_r 4142.000, elapsed 26.988 s, epsilon=0.87\n",
      "Test Epoch 200000, Total reward 3321, steps 35\n",
      "Episode 210000, avg_s 35.000, avg_tot_r -713.356, max_tot_r 4111.125, elapsed 27.050 s, epsilon=0.87\n",
      "Test Epoch 210000, Total reward 3321, steps 35\n",
      "Episode 220000, avg_s 34.998, avg_tot_r -733.534, max_tot_r 4430.375, elapsed 27.275 s, epsilon=0.86\n",
      "Test Epoch 220000, Total reward 3321, steps 35\n",
      "Episode 230000, avg_s 35.000, avg_tot_r -684.396, max_tot_r 4461.000, elapsed 27.288 s, epsilon=0.86\n",
      "Test Epoch 230000, Total reward 3321, steps 35\n",
      "Episode 240000, avg_s 34.999, avg_tot_r -687.721, max_tot_r 4559.375, elapsed 27.146 s, epsilon=0.86\n",
      "Test Epoch 240000, Total reward 3321, steps 35\n",
      "Episode 250000, avg_s 35.000, avg_tot_r -675.609, max_tot_r 4397.250, elapsed 27.582 s, epsilon=0.86\n",
      "Test Epoch 250000, Total reward 3321, steps 35\n",
      "Episode 260000, avg_s 34.999, avg_tot_r -668.765, max_tot_r 4142.750, elapsed 28.493 s, epsilon=0.86\n",
      "Test Epoch 260000, Total reward 3321, steps 35\n",
      "Episode 270000, avg_s 35.000, avg_tot_r -621.203, max_tot_r 4492.125, elapsed 29.467 s, epsilon=0.86\n",
      "Test Epoch 270000, Total reward 3575, steps 35\n",
      "Episode 280000, avg_s 34.999, avg_tot_r -639.417, max_tot_r 4191.062, elapsed 28.175 s, epsilon=0.86\n",
      "Test Epoch 280000, Total reward 3575, steps 35\n",
      "Episode 290000, avg_s 35.000, avg_tot_r -637.013, max_tot_r 4396.250, elapsed 28.703 s, epsilon=0.85\n",
      "Test Epoch 290000, Total reward 3575, steps 35\n",
      "Episode 300000, avg_s 34.999, avg_tot_r -611.613, max_tot_r 4718.000, elapsed 28.917 s, epsilon=0.85\n",
      "Test Epoch 300000, Total reward 3575, steps 35\n",
      "Episode 310000, avg_s 35.000, avg_tot_r -589.967, max_tot_r 4477.938, elapsed 29.054 s, epsilon=0.85\n",
      "Test Epoch 310000, Total reward 3321, steps 35\n",
      "Episode 320000, avg_s 35.000, avg_tot_r -569.276, max_tot_r 4460.250, elapsed 27.344 s, epsilon=0.85\n",
      "Test Epoch 320000, Total reward 3575, steps 35\n",
      "Episode 330000, avg_s 34.999, avg_tot_r -562.722, max_tot_r 4301.875, elapsed 26.874 s, epsilon=0.85\n",
      "Test Epoch 330000, Total reward 3575, steps 35\n",
      "Episode 340000, avg_s 34.999, avg_tot_r -557.248, max_tot_r 4303.750, elapsed 27.713 s, epsilon=0.85\n",
      "Test Epoch 340000, Total reward 3321, steps 35\n",
      "Episode 350000, avg_s 35.000, avg_tot_r -544.734, max_tot_r 4303.125, elapsed 27.654 s, epsilon=0.84\n",
      "Test Epoch 350000, Total reward 3575, steps 35\n",
      "Episode 360000, avg_s 35.000, avg_tot_r -550.290, max_tot_r 4381.062, elapsed 27.584 s, epsilon=0.84\n",
      "Test Epoch 360000, Total reward 3575, steps 35\n",
      "Episode 370000, avg_s 35.000, avg_tot_r -492.174, max_tot_r 4525.000, elapsed 32.478 s, epsilon=0.84\n",
      "Test Epoch 370000, Total reward 3575, steps 35\n",
      "Episode 380000, avg_s 35.000, avg_tot_r -472.247, max_tot_r 4484.656, elapsed 33.786 s, epsilon=0.84\n",
      "Test Epoch 380000, Total reward 3575, steps 35\n",
      "Episode 390000, avg_s 34.998, avg_tot_r -465.482, max_tot_r 4383.562, elapsed 31.179 s, epsilon=0.84\n",
      "Test Epoch 390000, Total reward 3321, steps 35\n",
      "Episode 400000, avg_s 35.000, avg_tot_r -495.334, max_tot_r 4271.250, elapsed 31.869 s, epsilon=0.84\n",
      "Test Epoch 400000, Total reward 3575, steps 35\n",
      "Episode 410000, avg_s 34.999, avg_tot_r -450.132, max_tot_r 4527.125, elapsed 30.611 s, epsilon=0.83\n",
      "Test Epoch 410000, Total reward 3829, steps 35\n",
      "Episode 420000, avg_s 35.000, avg_tot_r -452.675, max_tot_r 4780.000, elapsed 30.032 s, epsilon=0.83\n",
      "Test Epoch 420000, Total reward 3321, steps 35\n",
      "Episode 430000, avg_s 34.999, avg_tot_r -418.496, max_tot_r 4622.125, elapsed 29.797 s, epsilon=0.83\n",
      "Test Epoch 430000, Total reward 3321, steps 35\n",
      "Episode 440000, avg_s 35.000, avg_tot_r -441.872, max_tot_r 4620.125, elapsed 30.808 s, epsilon=0.83\n",
      "Test Epoch 440000, Total reward 3829, steps 35\n",
      "Episode 450000, avg_s 34.999, avg_tot_r -399.735, max_tot_r 4780.000, elapsed 31.242 s, epsilon=0.83\n",
      "Test Epoch 450000, Total reward 3321, steps 35\n",
      "Episode 460000, avg_s 35.000, avg_tot_r -373.683, max_tot_r 4812.375, elapsed 30.698 s, epsilon=0.83\n",
      "Test Epoch 460000, Total reward 3829, steps 35\n",
      "Episode 470000, avg_s 35.000, avg_tot_r -359.394, max_tot_r 4798.062, elapsed 30.463 s, epsilon=0.82\n",
      "Test Epoch 470000, Total reward 3321, steps 35\n",
      "Episode 480000, avg_s 34.998, avg_tot_r -361.679, max_tot_r 4429.375, elapsed 30.138 s, epsilon=0.82\n",
      "Test Epoch 480000, Total reward 3575, steps 35\n",
      "Episode 490000, avg_s 35.000, avg_tot_r -373.004, max_tot_r 4748.875, elapsed 31.501 s, epsilon=0.82\n",
      "Test Epoch 490000, Total reward 3829, steps 35\n",
      "Episode 500000, avg_s 35.000, avg_tot_r -348.097, max_tot_r 4653.750, elapsed 30.468 s, epsilon=0.82\n",
      "Test Epoch 500000, Total reward 3575, steps 35\n",
      "Episode 510000, avg_s 35.000, avg_tot_r -315.453, max_tot_r 4747.875, elapsed 31.325 s, epsilon=0.82\n",
      "Test Epoch 510000, Total reward 3575, steps 35\n",
      "Episode 520000, avg_s 35.000, avg_tot_r -270.859, max_tot_r 4907.750, elapsed 30.809 s, epsilon=0.82\n",
      "Test Epoch 520000, Total reward 3829, steps 35\n",
      "Episode 530000, avg_s 35.000, avg_tot_r -285.076, max_tot_r 4700.312, elapsed 30.714 s, epsilon=0.82\n",
      "Test Epoch 530000, Total reward 3829, steps 35\n",
      "Episode 540000, avg_s 35.000, avg_tot_r -283.979, max_tot_r 4779.750, elapsed 30.396 s, epsilon=0.81\n",
      "Test Epoch 540000, Total reward 3575, steps 35\n",
      "Episode 550000, avg_s 35.000, avg_tot_r -263.828, max_tot_r 5194.375, elapsed 31.696 s, epsilon=0.81\n",
      "Test Epoch 550000, Total reward 4083, steps 35\n",
      "Episode 560000, avg_s 34.999, avg_tot_r -238.540, max_tot_r 4428.875, elapsed 30.624 s, epsilon=0.81\n",
      "Test Epoch 560000, Total reward 4083, steps 35\n",
      "Episode 570000, avg_s 35.000, avg_tot_r -218.871, max_tot_r 4907.500, elapsed 30.484 s, epsilon=0.81\n",
      "Test Epoch 570000, Total reward 4083, steps 35\n",
      "Episode 580000, avg_s 35.000, avg_tot_r -223.258, max_tot_r 4749.375, elapsed 29.271 s, epsilon=0.81\n",
      "Test Epoch 580000, Total reward 3829, steps 35\n",
      "Episode 590000, avg_s 35.000, avg_tot_r -186.417, max_tot_r 4652.500, elapsed 28.982 s, epsilon=0.81\n",
      "Test Epoch 590000, Total reward 4083, steps 35\n",
      "Episode 600000, avg_s 35.000, avg_tot_r -176.579, max_tot_r 4843.750, elapsed 29.292 s, epsilon=0.80\n",
      "Test Epoch 600000, Total reward 4083, steps 35\n",
      "Episode 610000, avg_s 34.999, avg_tot_r -157.533, max_tot_r 4652.750, elapsed 27.119 s, epsilon=0.80\n",
      "Test Epoch 610000, Total reward 4083, steps 35\n",
      "Episode 620000, avg_s 35.000, avg_tot_r -178.943, max_tot_r 5069.625, elapsed 27.257 s, epsilon=0.80\n",
      "Test Epoch 620000, Total reward 4083, steps 35\n",
      "Episode 630000, avg_s 35.000, avg_tot_r -139.955, max_tot_r 4684.625, elapsed 27.021 s, epsilon=0.80\n",
      "Test Epoch 630000, Total reward 3829, steps 35\n",
      "Episode 640000, avg_s 35.000, avg_tot_r -114.335, max_tot_r 5035.250, elapsed 27.496 s, epsilon=0.80\n",
      "Test Epoch 640000, Total reward 3575, steps 35\n",
      "Episode 650000, avg_s 35.000, avg_tot_r -117.471, max_tot_r 4716.500, elapsed 27.629 s, epsilon=0.80\n",
      "Test Epoch 650000, Total reward 4083, steps 35\n",
      "Episode 660000, avg_s 35.000, avg_tot_r -106.556, max_tot_r 4779.000, elapsed 28.004 s, epsilon=0.79\n",
      "Test Epoch 660000, Total reward 4083, steps 35\n",
      "Episode 670000, avg_s 34.999, avg_tot_r -89.960, max_tot_r 4908.500, elapsed 28.195 s, epsilon=0.79\n",
      "Test Epoch 670000, Total reward 4337, steps 35\n",
      "Episode 680000, avg_s 35.000, avg_tot_r -64.672, max_tot_r 4971.000, elapsed 27.896 s, epsilon=0.79\n",
      "Test Epoch 680000, Total reward 4083, steps 35\n",
      "Episode 690000, avg_s 35.000, avg_tot_r -49.738, max_tot_r 4907.000, elapsed 28.086 s, epsilon=0.79\n",
      "Test Epoch 690000, Total reward 4337, steps 35\n",
      "Episode 700000, avg_s 34.999, avg_tot_r -4.802, max_tot_r 5226.250, elapsed 28.444 s, epsilon=0.79\n",
      "Test Epoch 700000, Total reward 4083, steps 35\n",
      "Episode 710000, avg_s 35.000, avg_tot_r 24.655, max_tot_r 5418.000, elapsed 27.281 s, epsilon=0.79\n",
      "Test Epoch 710000, Total reward 3829, steps 35\n",
      "Episode 720000, avg_s 35.000, avg_tot_r -9.144, max_tot_r 5481.250, elapsed 26.905 s, epsilon=0.78\n",
      "Test Epoch 720000, Total reward 4083, steps 35\n",
      "Episode 730000, avg_s 35.000, avg_tot_r 9.306, max_tot_r 4687.250, elapsed 27.233 s, epsilon=0.78\n",
      "Test Epoch 730000, Total reward 4337, steps 35\n",
      "Episode 740000, avg_s 35.000, avg_tot_r 60.325, max_tot_r 5227.500, elapsed 27.565 s, epsilon=0.78\n",
      "Test Epoch 740000, Total reward 4337, steps 35\n",
      "Episode 750000, avg_s 34.999, avg_tot_r 55.184, max_tot_r 5354.250, elapsed 28.174 s, epsilon=0.78\n",
      "Test Epoch 750000, Total reward 4337, steps 35\n",
      "Episode 760000, avg_s 35.000, avg_tot_r 100.638, max_tot_r 5067.625, elapsed 27.634 s, epsilon=0.78\n",
      "Test Epoch 760000, Total reward 4337, steps 35\n",
      "Episode 770000, avg_s 35.000, avg_tot_r 100.047, max_tot_r 4748.125, elapsed 27.935 s, epsilon=0.78\n",
      "Test Epoch 770000, Total reward 4083, steps 35\n",
      "Episode 780000, avg_s 35.000, avg_tot_r 111.658, max_tot_r 5100.000, elapsed 27.834 s, epsilon=0.78\n",
      "Test Epoch 780000, Total reward 3321, steps 35\n",
      "Episode 790000, avg_s 35.000, avg_tot_r 129.042, max_tot_r 5099.250, elapsed 27.372 s, epsilon=0.77\n",
      "Test Epoch 790000, Total reward 4083, steps 35\n",
      "Episode 800000, avg_s 34.999, avg_tot_r 106.746, max_tot_r 5164.375, elapsed 27.153 s, epsilon=0.77\n",
      "Test Epoch 800000, Total reward 4337, steps 35\n",
      "Episode 810000, avg_s 35.000, avg_tot_r 150.513, max_tot_r 5036.750, elapsed 27.319 s, epsilon=0.77\n",
      "Test Epoch 810000, Total reward 4337, steps 35\n",
      "Episode 820000, avg_s 35.000, avg_tot_r 173.408, max_tot_r 5266.594, elapsed 27.184 s, epsilon=0.77\n",
      "Test Epoch 820000, Total reward 4337, steps 35\n",
      "Episode 830000, avg_s 35.000, avg_tot_r 186.290, max_tot_r 5418.000, elapsed 27.271 s, epsilon=0.77\n",
      "Test Epoch 830000, Total reward 4083, steps 35\n",
      "Episode 840000, avg_s 35.000, avg_tot_r 196.501, max_tot_r 5211.062, elapsed 27.370 s, epsilon=0.77\n",
      "Test Epoch 840000, Total reward 4337, steps 35\n",
      "Episode 850000, avg_s 35.000, avg_tot_r 227.567, max_tot_r 5417.500, elapsed 27.192 s, epsilon=0.76\n",
      "Test Epoch 850000, Total reward 4337, steps 35\n",
      "Episode 860000, avg_s 35.000, avg_tot_r 252.137, max_tot_r 5005.625, elapsed 27.457 s, epsilon=0.76\n",
      "Test Epoch 860000, Total reward 3829, steps 35\n",
      "Episode 870000, avg_s 35.000, avg_tot_r 255.163, max_tot_r 5021.312, elapsed 27.718 s, epsilon=0.76\n",
      "Test Epoch 870000, Total reward 3829, steps 35\n",
      "Episode 880000, avg_s 35.000, avg_tot_r 308.778, max_tot_r 4971.500, elapsed 27.511 s, epsilon=0.76\n",
      "Test Epoch 880000, Total reward 4337, steps 35\n",
      "Episode 890000, avg_s 35.000, avg_tot_r 296.700, max_tot_r 5577.125, elapsed 27.197 s, epsilon=0.76\n",
      "Test Epoch 890000, Total reward 4591, steps 35\n",
      "Episode 900000, avg_s 35.000, avg_tot_r 297.335, max_tot_r 5355.750, elapsed 27.411 s, epsilon=0.76\n",
      "Test Epoch 900000, Total reward 4337, steps 35\n",
      "Episode 910000, avg_s 35.000, avg_tot_r 353.860, max_tot_r 5608.750, elapsed 27.270 s, epsilon=0.75\n",
      "Test Epoch 910000, Total reward 4591, steps 35\n",
      "Episode 920000, avg_s 35.000, avg_tot_r 324.617, max_tot_r 5131.125, elapsed 27.525 s, epsilon=0.75\n",
      "Test Epoch 920000, Total reward 4337, steps 35\n",
      "Episode 930000, avg_s 35.000, avg_tot_r 355.479, max_tot_r 5371.438, elapsed 27.171 s, epsilon=0.75\n",
      "Test Epoch 930000, Total reward 4591, steps 35\n",
      "Episode 940000, avg_s 35.000, avg_tot_r 386.986, max_tot_r 5258.125, elapsed 27.457 s, epsilon=0.75\n",
      "Test Epoch 940000, Total reward 4083, steps 35\n",
      "Episode 950000, avg_s 35.000, avg_tot_r 385.793, max_tot_r 5003.375, elapsed 27.851 s, epsilon=0.75\n",
      "Test Epoch 950000, Total reward 4337, steps 35\n",
      "Episode 960000, avg_s 35.000, avg_tot_r 433.979, max_tot_r 5259.375, elapsed 27.834 s, epsilon=0.75\n",
      "Test Epoch 960000, Total reward 3575, steps 35\n",
      "Episode 970000, avg_s 35.000, avg_tot_r 409.623, max_tot_r 5817.188, elapsed 27.509 s, epsilon=0.74\n",
      "Test Epoch 970000, Total reward 4337, steps 35\n",
      "Episode 980000, avg_s 35.000, avg_tot_r 412.539, max_tot_r 5354.250, elapsed 27.489 s, epsilon=0.74\n",
      "Test Epoch 980000, Total reward 4591, steps 35\n",
      "Episode 990000, avg_s 35.000, avg_tot_r 463.956, max_tot_r 5385.875, elapsed 28.023 s, epsilon=0.74\n",
      "Test Epoch 990000, Total reward 4591, steps 35\n",
      "Episode 1000000, avg_s 35.000, avg_tot_r 457.191, max_tot_r 4973.750, elapsed 27.384 s, epsilon=0.74\n",
      "Test Epoch 1000000, Total reward 4591, steps 35\n",
      "Episode 1010000, avg_s 35.000, avg_tot_r 519.150, max_tot_r 5380.531, elapsed 28.081 s, epsilon=0.74\n",
      "Test Epoch 1010000, Total reward 4591, steps 35\n",
      "Episode 1020000, avg_s 35.000, avg_tot_r 536.790, max_tot_r 5736.750, elapsed 27.399 s, epsilon=0.74\n",
      "Test Epoch 1020000, Total reward 4591, steps 35\n",
      "Episode 1030000, avg_s 34.999, avg_tot_r 560.697, max_tot_r 5865.625, elapsed 27.502 s, epsilon=0.74\n",
      "Test Epoch 1030000, Total reward 4591, steps 35\n",
      "Episode 1040000, avg_s 35.000, avg_tot_r 557.596, max_tot_r 5704.625, elapsed 27.686 s, epsilon=0.73\n",
      "Test Epoch 1040000, Total reward 4083, steps 35\n",
      "Episode 1050000, avg_s 35.000, avg_tot_r 571.737, max_tot_r 5514.375, elapsed 27.384 s, epsilon=0.73\n",
      "Test Epoch 1050000, Total reward 4337, steps 35\n",
      "Episode 1060000, avg_s 35.000, avg_tot_r 587.184, max_tot_r 5579.875, elapsed 27.686 s, epsilon=0.73\n",
      "Test Epoch 1060000, Total reward 4337, steps 35\n",
      "Episode 1070000, avg_s 35.000, avg_tot_r 605.833, max_tot_r 5610.750, elapsed 28.034 s, epsilon=0.73\n",
      "Test Epoch 1070000, Total reward 4083, steps 35\n",
      "Episode 1080000, avg_s 35.000, avg_tot_r 612.879, max_tot_r 5290.000, elapsed 36.577 s, epsilon=0.73\n",
      "Test Epoch 1080000, Total reward 4591, steps 35\n",
      "Episode 1090000, avg_s 35.000, avg_tot_r 642.093, max_tot_r 5401.312, elapsed 33.659 s, epsilon=0.73\n",
      "Test Epoch 1090000, Total reward 4083, steps 35\n",
      "Episode 1100000, avg_s 35.000, avg_tot_r 661.341, max_tot_r 5530.062, elapsed 30.968 s, epsilon=0.72\n",
      "Test Epoch 1100000, Total reward 4591, steps 35\n",
      "Episode 1110000, avg_s 34.999, avg_tot_r 658.914, max_tot_r 5514.750, elapsed 34.876 s, epsilon=0.72\n",
      "Test Epoch 1110000, Total reward 4591, steps 35\n",
      "Episode 1120000, avg_s 35.000, avg_tot_r 683.960, max_tot_r 5832.625, elapsed 33.156 s, epsilon=0.72\n",
      "Test Epoch 1120000, Total reward 4083, steps 35\n",
      "Episode 1130000, avg_s 35.000, avg_tot_r 696.596, max_tot_r 5418.000, elapsed 32.659 s, epsilon=0.72\n",
      "Test Epoch 1130000, Total reward 4591, steps 35\n",
      "Episode 1140000, avg_s 35.000, avg_tot_r 728.179, max_tot_r 5226.750, elapsed 40.939 s, epsilon=0.72\n",
      "Test Epoch 1140000, Total reward 4337, steps 35\n",
      "Episode 1150000, avg_s 35.000, avg_tot_r 737.590, max_tot_r 5897.125, elapsed 37.398 s, epsilon=0.72\n",
      "Test Epoch 1150000, Total reward 4083, steps 35\n",
      "Episode 1160000, avg_s 35.000, avg_tot_r 755.891, max_tot_r 5912.562, elapsed 47.218 s, epsilon=0.71\n",
      "Test Epoch 1160000, Total reward 4845, steps 35\n",
      "Episode 1170000, avg_s 35.000, avg_tot_r 787.502, max_tot_r 5896.875, elapsed 47.684 s, epsilon=0.71\n",
      "Test Epoch 1170000, Total reward 4591, steps 35\n",
      "Episode 1180000, avg_s 35.000, avg_tot_r 813.268, max_tot_r 5737.250, elapsed 45.440 s, epsilon=0.71\n",
      "Test Epoch 1180000, Total reward 4591, steps 35\n",
      "Episode 1190000, avg_s 35.000, avg_tot_r 831.206, max_tot_r 5513.875, elapsed 48.201 s, epsilon=0.71\n",
      "Test Epoch 1190000, Total reward 4337, steps 35\n",
      "Episode 1200000, avg_s 35.000, avg_tot_r 850.754, max_tot_r 5836.125, elapsed 39.653 s, epsilon=0.71\n",
      "Test Epoch 1200000, Total reward 4845, steps 35\n",
      "Episode 1210000, avg_s 35.000, avg_tot_r 851.280, max_tot_r 5608.000, elapsed 47.697 s, epsilon=0.71\n",
      "Test Epoch 1210000, Total reward 4591, steps 35\n",
      "Episode 1220000, avg_s 35.000, avg_tot_r 874.666, max_tot_r 5481.000, elapsed 37.393 s, epsilon=0.70\n",
      "Test Epoch 1220000, Total reward 4845, steps 35\n",
      "Episode 1230000, avg_s 35.000, avg_tot_r 889.360, max_tot_r 5704.625, elapsed 30.617 s, epsilon=0.70\n",
      "Test Epoch 1230000, Total reward 4845, steps 35\n",
      "Episode 1240000, avg_s 35.000, avg_tot_r 900.621, max_tot_r 5737.250, elapsed 29.714 s, epsilon=0.70\n",
      "Test Epoch 1240000, Total reward 4845, steps 35\n",
      "Episode 1250000, avg_s 35.000, avg_tot_r 879.939, max_tot_r 5641.125, elapsed 29.626 s, epsilon=0.70\n",
      "Test Epoch 1250000, Total reward 4591, steps 35\n",
      "Episode 1260000, avg_s 35.000, avg_tot_r 950.453, max_tot_r 6151.875, elapsed 29.527 s, epsilon=0.70\n",
      "Test Epoch 1260000, Total reward 4845, steps 35\n",
      "Episode 1270000, avg_s 35.000, avg_tot_r 954.303, max_tot_r 5608.750, elapsed 29.619 s, epsilon=0.70\n",
      "Test Epoch 1270000, Total reward 4591, steps 35\n",
      "Episode 1280000, avg_s 35.000, avg_tot_r 963.122, max_tot_r 5608.750, elapsed 30.270 s, epsilon=0.70\n",
      "Test Epoch 1280000, Total reward 4591, steps 35\n",
      "Episode 1290000, avg_s 35.000, avg_tot_r 989.819, max_tot_r 5483.750, elapsed 30.001 s, epsilon=0.69\n",
      "Test Epoch 1290000, Total reward 4845, steps 35\n",
      "Episode 1300000, avg_s 35.000, avg_tot_r 1011.576, max_tot_r 5769.375, elapsed 29.973 s, epsilon=0.69\n",
      "Test Epoch 1300000, Total reward 4845, steps 35\n",
      "Episode 1310000, avg_s 35.000, avg_tot_r 1059.971, max_tot_r 5705.375, elapsed 30.959 s, epsilon=0.69\n",
      "Test Epoch 1310000, Total reward 4845, steps 35\n",
      "Episode 1320000, avg_s 35.000, avg_tot_r 1085.435, max_tot_r 6119.250, elapsed 30.405 s, epsilon=0.69\n",
      "Test Epoch 1320000, Total reward 4337, steps 35\n",
      "Episode 1330000, avg_s 35.000, avg_tot_r 1085.271, max_tot_r 5801.250, elapsed 30.488 s, epsilon=0.69\n",
      "Test Epoch 1330000, Total reward 4845, steps 35\n",
      "Episode 1340000, avg_s 35.000, avg_tot_r 1120.313, max_tot_r 5658.062, elapsed 30.542 s, epsilon=0.69\n",
      "Test Epoch 1340000, Total reward 4845, steps 35\n",
      "Episode 1350000, avg_s 35.000, avg_tot_r 1127.237, max_tot_r 5736.750, elapsed 29.568 s, epsilon=0.68\n",
      "Test Epoch 1350000, Total reward 4845, steps 35\n",
      "Episode 1360000, avg_s 35.000, avg_tot_r 1130.639, max_tot_r 5848.812, elapsed 29.719 s, epsilon=0.68\n",
      "Test Epoch 1360000, Total reward 4845, steps 35\n",
      "Episode 1370000, avg_s 35.000, avg_tot_r 1150.786, max_tot_r 5736.250, elapsed 29.791 s, epsilon=0.68\n",
      "Test Epoch 1370000, Total reward 4591, steps 35\n",
      "Episode 1380000, avg_s 35.000, avg_tot_r 1150.600, max_tot_r 6439.000, elapsed 28.878 s, epsilon=0.68\n",
      "Test Epoch 1380000, Total reward 4083, steps 35\n",
      "Episode 1390000, avg_s 35.000, avg_tot_r 1185.043, max_tot_r 5737.000, elapsed 29.486 s, epsilon=0.68\n",
      "Test Epoch 1390000, Total reward 4591, steps 35\n",
      "Episode 1400000, avg_s 35.000, avg_tot_r 1199.341, max_tot_r 5737.250, elapsed 29.974 s, epsilon=0.68\n",
      "Test Epoch 1400000, Total reward 4591, steps 35\n",
      "Episode 1410000, avg_s 35.000, avg_tot_r 1232.876, max_tot_r 6087.875, elapsed 29.541 s, epsilon=0.67\n",
      "Test Epoch 1410000, Total reward 4845, steps 35\n",
      "Episode 1420000, avg_s 35.000, avg_tot_r 1258.096, max_tot_r 6056.250, elapsed 29.666 s, epsilon=0.67\n",
      "Test Epoch 1420000, Total reward 4845, steps 35\n",
      "Episode 1430000, avg_s 35.000, avg_tot_r 1259.993, max_tot_r 5673.000, elapsed 29.806 s, epsilon=0.67\n",
      "Test Epoch 1430000, Total reward 4337, steps 35\n",
      "Episode 1440000, avg_s 35.000, avg_tot_r 1263.631, max_tot_r 5801.250, elapsed 29.371 s, epsilon=0.67\n",
      "Test Epoch 1440000, Total reward 5099, steps 35\n",
      "Episode 1450000, avg_s 35.000, avg_tot_r 1305.763, max_tot_r 5912.562, elapsed 28.826 s, epsilon=0.67\n",
      "Test Epoch 1450000, Total reward 5099, steps 35\n",
      "Episode 1460000, avg_s 35.000, avg_tot_r 1328.238, max_tot_r 5849.812, elapsed 29.636 s, epsilon=0.67\n",
      "Test Epoch 1460000, Total reward 5099, steps 35\n",
      "Episode 1470000, avg_s 35.000, avg_tot_r 1324.483, max_tot_r 6183.500, elapsed 30.548 s, epsilon=0.66\n",
      "Test Epoch 1470000, Total reward 5099, steps 35\n",
      "Episode 1480000, avg_s 35.000, avg_tot_r 1369.370, max_tot_r 6120.000, elapsed 30.248 s, epsilon=0.66\n",
      "Test Epoch 1480000, Total reward 5099, steps 35\n",
      "Episode 1490000, avg_s 35.000, avg_tot_r 1397.008, max_tot_r 5897.125, elapsed 29.814 s, epsilon=0.66\n",
      "Test Epoch 1490000, Total reward 5099, steps 35\n",
      "Episode 1500000, avg_s 35.000, avg_tot_r 1376.156, max_tot_r 5929.250, elapsed 29.630 s, epsilon=0.66\n",
      "Test Epoch 1500000, Total reward 4591, steps 35\n",
      "Episode 1510000, avg_s 35.000, avg_tot_r 1410.868, max_tot_r 5737.250, elapsed 29.946 s, epsilon=0.66\n",
      "Test Epoch 1510000, Total reward 5099, steps 35\n",
      "Episode 1520000, avg_s 35.000, avg_tot_r 1425.741, max_tot_r 5993.000, elapsed 29.960 s, epsilon=0.66\n",
      "Test Epoch 1520000, Total reward 5099, steps 35\n",
      "Episode 1530000, avg_s 35.000, avg_tot_r 1438.134, max_tot_r 6246.750, elapsed 30.515 s, epsilon=0.66\n",
      "Test Epoch 1530000, Total reward 4845, steps 35\n",
      "Episode 1540000, avg_s 35.000, avg_tot_r 1471.507, max_tot_r 5960.125, elapsed 29.470 s, epsilon=0.65\n",
      "Test Epoch 1540000, Total reward 5099, steps 35\n",
      "Episode 1550000, avg_s 35.000, avg_tot_r 1487.074, max_tot_r 5928.000, elapsed 28.972 s, epsilon=0.65\n",
      "Test Epoch 1550000, Total reward 5099, steps 35\n",
      "Episode 1560000, avg_s 35.000, avg_tot_r 1520.277, max_tot_r 5864.250, elapsed 30.010 s, epsilon=0.65\n",
      "Test Epoch 1560000, Total reward 4845, steps 35\n",
      "Episode 1570000, avg_s 35.000, avg_tot_r 1537.664, max_tot_r 6310.750, elapsed 30.183 s, epsilon=0.65\n",
      "Test Epoch 1570000, Total reward 4845, steps 35\n",
      "Episode 1580000, avg_s 35.000, avg_tot_r 1544.100, max_tot_r 6215.375, elapsed 30.370 s, epsilon=0.65\n",
      "Test Epoch 1580000, Total reward 5099, steps 35\n",
      "Episode 1590000, avg_s 35.000, avg_tot_r 1554.614, max_tot_r 6247.250, elapsed 29.750 s, epsilon=0.65\n",
      "Test Epoch 1590000, Total reward 4337, steps 35\n",
      "Episode 1600000, avg_s 35.000, avg_tot_r 1596.099, max_tot_r 6215.375, elapsed 29.694 s, epsilon=0.64\n",
      "Test Epoch 1600000, Total reward 5099, steps 35\n",
      "Episode 1610000, avg_s 35.000, avg_tot_r 1615.662, max_tot_r 6374.000, elapsed 30.382 s, epsilon=0.64\n",
      "Test Epoch 1610000, Total reward 4845, steps 35\n",
      "Episode 1620000, avg_s 35.000, avg_tot_r 1613.146, max_tot_r 5992.250, elapsed 29.904 s, epsilon=0.64\n",
      "Test Epoch 1620000, Total reward 5099, steps 35\n",
      "Episode 1630000, avg_s 35.000, avg_tot_r 1660.040, max_tot_r 6246.750, elapsed 30.076 s, epsilon=0.64\n",
      "Test Epoch 1630000, Total reward 5099, steps 35\n",
      "Episode 1640000, avg_s 35.000, avg_tot_r 1671.709, max_tot_r 5865.750, elapsed 30.340 s, epsilon=0.64\n",
      "Test Epoch 1640000, Total reward 4845, steps 35\n",
      "Episode 1650000, avg_s 35.000, avg_tot_r 1678.515, max_tot_r 6182.750, elapsed 29.868 s, epsilon=0.64\n",
      "Test Epoch 1650000, Total reward 4591, steps 35\n",
      "Episode 1660000, avg_s 35.000, avg_tot_r 1707.063, max_tot_r 6310.750, elapsed 32.525 s, epsilon=0.63\n",
      "Test Epoch 1660000, Total reward 4845, steps 35\n",
      "Episode 1670000, avg_s 35.000, avg_tot_r 1745.732, max_tot_r 6360.812, elapsed 33.715 s, epsilon=0.63\n",
      "Test Epoch 1670000, Total reward 5099, steps 35\n",
      "Episode 1680000, avg_s 35.000, avg_tot_r 1736.416, max_tot_r 5928.500, elapsed 33.939 s, epsilon=0.63\n",
      "Test Epoch 1680000, Total reward 5099, steps 35\n",
      "Episode 1690000, avg_s 35.000, avg_tot_r 1754.919, max_tot_r 5991.500, elapsed 33.601 s, epsilon=0.63\n",
      "Test Epoch 1690000, Total reward 5099, steps 35\n",
      "Episode 1700000, avg_s 35.000, avg_tot_r 1763.100, max_tot_r 6088.875, elapsed 33.552 s, epsilon=0.63\n",
      "Test Epoch 1700000, Total reward 5099, steps 35\n",
      "Episode 1710000, avg_s 35.000, avg_tot_r 1820.801, max_tot_r 6375.750, elapsed 33.982 s, epsilon=0.63\n",
      "Test Epoch 1710000, Total reward 5099, steps 35\n",
      "Episode 1720000, avg_s 35.000, avg_tot_r 1822.392, max_tot_r 6279.875, elapsed 32.155 s, epsilon=0.62\n",
      "Test Epoch 1720000, Total reward 4845, steps 35\n",
      "Episode 1730000, avg_s 35.000, avg_tot_r 1827.030, max_tot_r 6023.875, elapsed 31.229 s, epsilon=0.62\n",
      "Test Epoch 1730000, Total reward 5099, steps 35\n",
      "Episode 1740000, avg_s 35.000, avg_tot_r 1879.967, max_tot_r 6502.000, elapsed 32.421 s, epsilon=0.62\n",
      "Test Epoch 1740000, Total reward 5099, steps 35\n",
      "Episode 1750000, avg_s 35.000, avg_tot_r 1891.883, max_tot_r 6183.000, elapsed 33.561 s, epsilon=0.62\n",
      "Test Epoch 1750000, Total reward 5353, steps 35\n",
      "Episode 1760000, avg_s 35.000, avg_tot_r 1933.241, max_tot_r 6566.750, elapsed 31.860 s, epsilon=0.62\n",
      "Test Epoch 1760000, Total reward 5353, steps 35\n",
      "Episode 1770000, avg_s 35.000, avg_tot_r 1924.210, max_tot_r 6246.500, elapsed 31.123 s, epsilon=0.62\n",
      "Test Epoch 1770000, Total reward 5353, steps 35\n",
      "Episode 1780000, avg_s 35.000, avg_tot_r 1931.965, max_tot_r 6311.250, elapsed 31.888 s, epsilon=0.62\n",
      "Test Epoch 1780000, Total reward 4845, steps 35\n",
      "Episode 1790000, avg_s 35.000, avg_tot_r 1926.636, max_tot_r 6377.000, elapsed 33.051 s, epsilon=0.61\n",
      "Test Epoch 1790000, Total reward 5353, steps 35\n",
      "Episode 1800000, avg_s 35.000, avg_tot_r 1952.053, max_tot_r 6119.250, elapsed 32.887 s, epsilon=0.61\n",
      "Test Epoch 1800000, Total reward 5353, steps 35\n",
      "Episode 1810000, avg_s 35.000, avg_tot_r 1990.478, max_tot_r 6471.625, elapsed 31.689 s, epsilon=0.61\n",
      "Test Epoch 1810000, Total reward 5099, steps 35\n",
      "Episode 1820000, avg_s 35.000, avg_tot_r 2038.058, max_tot_r 6184.000, elapsed 31.300 s, epsilon=0.61\n",
      "Test Epoch 1820000, Total reward 5099, steps 35\n",
      "Episode 1830000, avg_s 35.000, avg_tot_r 2058.380, max_tot_r 6376.000, elapsed 32.463 s, epsilon=0.61\n",
      "Test Epoch 1830000, Total reward 5353, steps 35\n",
      "Episode 1840000, avg_s 35.000, avg_tot_r 2047.710, max_tot_r 6406.625, elapsed 32.585 s, epsilon=0.61\n",
      "Test Epoch 1840000, Total reward 5099, steps 35\n",
      "Episode 1850000, avg_s 35.000, avg_tot_r 2104.487, max_tot_r 6629.500, elapsed 32.432 s, epsilon=0.60\n",
      "Test Epoch 1850000, Total reward 5353, steps 35\n",
      "Episode 1860000, avg_s 35.000, avg_tot_r 2107.246, max_tot_r 6311.500, elapsed 31.563 s, epsilon=0.60\n",
      "Test Epoch 1860000, Total reward 5353, steps 35\n",
      "Episode 1870000, avg_s 35.000, avg_tot_r 2128.229, max_tot_r 6502.750, elapsed 31.498 s, epsilon=0.60\n",
      "Test Epoch 1870000, Total reward 5099, steps 35\n",
      "Episode 1880000, avg_s 35.000, avg_tot_r 2139.564, max_tot_r 6279.625, elapsed 32.724 s, epsilon=0.60\n",
      "Test Epoch 1880000, Total reward 5353, steps 35\n",
      "Episode 1890000, avg_s 35.000, avg_tot_r 2153.673, max_tot_r 6246.750, elapsed 33.427 s, epsilon=0.60\n",
      "Test Epoch 1890000, Total reward 5353, steps 35\n",
      "Episode 1900000, avg_s 35.000, avg_tot_r 2182.076, max_tot_r 6342.625, elapsed 32.443 s, epsilon=0.60\n",
      "Test Epoch 1900000, Total reward 5099, steps 35\n",
      "Episode 1910000, avg_s 35.000, avg_tot_r 2208.980, max_tot_r 6439.500, elapsed 31.365 s, epsilon=0.59\n",
      "Test Epoch 1910000, Total reward 5353, steps 35\n",
      "Episode 1920000, avg_s 35.000, avg_tot_r 2210.497, max_tot_r 6438.000, elapsed 33.267 s, epsilon=0.59\n",
      "Test Epoch 1920000, Total reward 5353, steps 35\n",
      "Episode 1930000, avg_s 35.000, avg_tot_r 2225.054, max_tot_r 6375.250, elapsed 32.840 s, epsilon=0.59\n",
      "Test Epoch 1930000, Total reward 5099, steps 35\n",
      "Episode 1940000, avg_s 35.000, avg_tot_r 2286.065, max_tot_r 6248.250, elapsed 31.953 s, epsilon=0.59\n",
      "Test Epoch 1940000, Total reward 5353, steps 35\n",
      "Episode 1950000, avg_s 35.000, avg_tot_r 2279.934, max_tot_r 6183.250, elapsed 31.544 s, epsilon=0.59\n",
      "Test Epoch 1950000, Total reward 5099, steps 35\n",
      "Episode 1960000, avg_s 35.000, avg_tot_r 2309.477, max_tot_r 6342.875, elapsed 32.946 s, epsilon=0.59\n",
      "Test Epoch 1960000, Total reward 5353, steps 35\n",
      "Episode 1970000, avg_s 35.000, avg_tot_r 2362.509, max_tot_r 6439.000, elapsed 33.229 s, epsilon=0.58\n",
      "Test Epoch 1970000, Total reward 4845, steps 35\n",
      "Episode 1980000, avg_s 35.000, avg_tot_r 2357.889, max_tot_r 6534.625, elapsed 31.691 s, epsilon=0.58\n",
      "Test Epoch 1980000, Total reward 5353, steps 35\n",
      "Episode 1990000, avg_s 35.000, avg_tot_r 2368.037, max_tot_r 6629.500, elapsed 31.410 s, epsilon=0.58\n",
      "Test Epoch 1990000, Total reward 5353, steps 35\n",
      "Episode 2000000, avg_s 35.000, avg_tot_r 2396.792, max_tot_r 6375.250, elapsed 31.707 s, epsilon=0.58\n",
      "Test Epoch 2000000, Total reward 5607, steps 35\n",
      "Episode 2010000, avg_s 35.000, avg_tot_r 2423.794, max_tot_r 6343.125, elapsed 33.444 s, epsilon=0.58\n",
      "Test Epoch 2010000, Total reward 5607, steps 35\n",
      "Episode 2020000, avg_s 35.000, avg_tot_r 2440.893, max_tot_r 6693.750, elapsed 33.040 s, epsilon=0.58\n",
      "Test Epoch 2020000, Total reward 5607, steps 35\n",
      "Episode 2030000, avg_s 35.000, avg_tot_r 2452.147, max_tot_r 6502.250, elapsed 32.401 s, epsilon=0.58\n",
      "Test Epoch 2030000, Total reward 5353, steps 35\n",
      "Episode 2040000, avg_s 35.000, avg_tot_r 2459.790, max_tot_r 6597.875, elapsed 33.472 s, epsilon=0.57\n",
      "Test Epoch 2040000, Total reward 5607, steps 35\n",
      "Episode 2050000, avg_s 35.000, avg_tot_r 2477.734, max_tot_r 6630.000, elapsed 33.918 s, epsilon=0.57\n",
      "Test Epoch 2050000, Total reward 4845, steps 35\n",
      "Episode 2060000, avg_s 35.000, avg_tot_r 2497.092, max_tot_r 6949.750, elapsed 33.167 s, epsilon=0.57\n",
      "Test Epoch 2060000, Total reward 5353, steps 35\n",
      "Episode 2070000, avg_s 35.000, avg_tot_r 2530.494, max_tot_r 6502.250, elapsed 31.859 s, epsilon=0.57\n",
      "Test Epoch 2070000, Total reward 5353, steps 35\n",
      "Episode 2080000, avg_s 35.000, avg_tot_r 2561.505, max_tot_r 6757.250, elapsed 31.187 s, epsilon=0.57\n",
      "Test Epoch 2080000, Total reward 5607, steps 35\n",
      "Episode 2090000, avg_s 35.000, avg_tot_r 2542.926, max_tot_r 6758.000, elapsed 31.950 s, epsilon=0.57\n",
      "Test Epoch 2090000, Total reward 5353, steps 35\n",
      "Episode 2100000, avg_s 35.000, avg_tot_r 2584.589, max_tot_r 6693.750, elapsed 32.940 s, epsilon=0.56\n",
      "Test Epoch 2100000, Total reward 4845, steps 35\n",
      "Episode 2110000, avg_s 35.000, avg_tot_r 2592.850, max_tot_r 6439.250, elapsed 33.649 s, epsilon=0.56\n",
      "Test Epoch 2110000, Total reward 5607, steps 35\n",
      "Episode 2120000, avg_s 35.000, avg_tot_r 2670.501, max_tot_r 6630.000, elapsed 31.809 s, epsilon=0.56\n",
      "Test Epoch 2120000, Total reward 5353, steps 35\n",
      "Episode 2130000, avg_s 35.000, avg_tot_r 2651.983, max_tot_r 6598.125, elapsed 28.585 s, epsilon=0.56\n",
      "Test Epoch 2130000, Total reward 5099, steps 35\n",
      "Episode 2140000, avg_s 35.000, avg_tot_r 2684.311, max_tot_r 6885.000, elapsed 28.958 s, epsilon=0.56\n",
      "Test Epoch 2140000, Total reward 5861, steps 35\n",
      "Episode 2150000, avg_s 35.000, avg_tot_r 2696.744, max_tot_r 6693.500, elapsed 29.694 s, epsilon=0.56\n",
      "Test Epoch 2150000, Total reward 5861, steps 35\n",
      "Episode 2160000, avg_s 35.000, avg_tot_r 2672.810, max_tot_r 6630.500, elapsed 32.204 s, epsilon=0.55\n",
      "Test Epoch 2160000, Total reward 5861, steps 35\n",
      "Episode 2170000, avg_s 35.000, avg_tot_r 2721.413, max_tot_r 6757.750, elapsed 35.235 s, epsilon=0.55\n",
      "Test Epoch 2170000, Total reward 5861, steps 35\n",
      "Episode 2180000, avg_s 35.000, avg_tot_r 2762.263, max_tot_r 6820.250, elapsed 30.268 s, epsilon=0.55\n",
      "Test Epoch 2180000, Total reward 5353, steps 35\n",
      "Episode 2190000, avg_s 35.000, avg_tot_r 2744.922, max_tot_r 6822.000, elapsed 29.607 s, epsilon=0.55\n",
      "Test Epoch 2190000, Total reward 5861, steps 35\n",
      "Episode 2200000, avg_s 35.000, avg_tot_r 2787.462, max_tot_r 6661.625, elapsed 31.128 s, epsilon=0.55\n",
      "Test Epoch 2200000, Total reward 5861, steps 35\n",
      "Episode 2210000, avg_s 35.000, avg_tot_r 2786.081, max_tot_r 6629.750, elapsed 31.123 s, epsilon=0.55\n",
      "Test Epoch 2210000, Total reward 5861, steps 35\n",
      "Episode 2220000, avg_s 35.000, avg_tot_r 2868.347, max_tot_r 6821.250, elapsed 30.052 s, epsilon=0.54\n",
      "Test Epoch 2220000, Total reward 5607, steps 35\n",
      "Episode 2230000, avg_s 35.000, avg_tot_r 2843.798, max_tot_r 6885.250, elapsed 29.591 s, epsilon=0.54\n",
      "Test Epoch 2230000, Total reward 5607, steps 35\n",
      "Episode 2240000, avg_s 35.000, avg_tot_r 2887.223, max_tot_r 6820.500, elapsed 30.267 s, epsilon=0.54\n",
      "Test Epoch 2240000, Total reward 5861, steps 35\n",
      "Episode 2250000, avg_s 35.000, avg_tot_r 2861.792, max_tot_r 6662.875, elapsed 30.808 s, epsilon=0.54\n",
      "Test Epoch 2250000, Total reward 5861, steps 35\n",
      "Episode 2260000, avg_s 35.000, avg_tot_r 2923.830, max_tot_r 6757.500, elapsed 30.648 s, epsilon=0.54\n",
      "Test Epoch 2260000, Total reward 5861, steps 35\n",
      "Episode 2270000, avg_s 35.000, avg_tot_r 2901.881, max_tot_r 7076.000, elapsed 30.366 s, epsilon=0.54\n",
      "Test Epoch 2270000, Total reward 5861, steps 35\n",
      "Episode 2280000, avg_s 35.000, avg_tot_r 2924.498, max_tot_r 6757.000, elapsed 30.918 s, epsilon=0.54\n",
      "Test Epoch 2280000, Total reward 5607, steps 35\n",
      "Episode 2290000, avg_s 35.000, avg_tot_r 2927.560, max_tot_r 6821.250, elapsed 29.596 s, epsilon=0.53\n",
      "Test Epoch 2290000, Total reward 5861, steps 35\n",
      "Episode 2300000, avg_s 35.000, avg_tot_r 2984.577, max_tot_r 6757.500, elapsed 31.003 s, epsilon=0.53\n",
      "Test Epoch 2300000, Total reward 5099, steps 35\n",
      "Episode 2310000, avg_s 35.000, avg_tot_r 2995.275, max_tot_r 7076.500, elapsed 30.072 s, epsilon=0.53\n",
      "Test Epoch 2310000, Total reward 6114, steps 35\n",
      "Episode 2320000, avg_s 35.000, avg_tot_r 3026.894, max_tot_r 7235.375, elapsed 30.670 s, epsilon=0.53\n",
      "Test Epoch 2320000, Total reward 5861, steps 35\n",
      "Episode 2330000, avg_s 35.000, avg_tot_r 3024.382, max_tot_r 7395.250, elapsed 30.527 s, epsilon=0.53\n",
      "Test Epoch 2330000, Total reward 5861, steps 35\n",
      "Episode 2340000, avg_s 35.000, avg_tot_r 3082.928, max_tot_r 7267.500, elapsed 29.602 s, epsilon=0.53\n",
      "Test Epoch 2340000, Total reward 5861, steps 35\n",
      "Episode 2350000, avg_s 35.000, avg_tot_r 3075.967, max_tot_r 6852.875, elapsed 30.537 s, epsilon=0.52\n",
      "Test Epoch 2350000, Total reward 6114, steps 35\n",
      "Episode 2360000, avg_s 35.000, avg_tot_r 3106.746, max_tot_r 6885.500, elapsed 35.127 s, epsilon=0.52\n",
      "Test Epoch 2360000, Total reward 6114, steps 35\n",
      "Episode 2370000, avg_s 35.000, avg_tot_r 3111.323, max_tot_r 6948.750, elapsed 44.292 s, epsilon=0.52\n",
      "Test Epoch 2370000, Total reward 5861, steps 35\n",
      "Episode 2380000, avg_s 35.000, avg_tot_r 3162.646, max_tot_r 7076.000, elapsed 34.078 s, epsilon=0.52\n",
      "Test Epoch 2380000, Total reward 5861, steps 35\n",
      "Episode 2390000, avg_s 35.000, avg_tot_r 3199.410, max_tot_r 7076.500, elapsed 39.967 s, epsilon=0.52\n",
      "Test Epoch 2390000, Total reward 5607, steps 35\n",
      "Episode 2400000, avg_s 35.000, avg_tot_r 3187.999, max_tot_r 7140.250, elapsed 33.894 s, epsilon=0.52\n",
      "Test Epoch 2400000, Total reward 6114, steps 35\n",
      "Episode 2410000, avg_s 35.000, avg_tot_r 3190.819, max_tot_r 7140.500, elapsed 34.194 s, epsilon=0.51\n",
      "Test Epoch 2410000, Total reward 6114, steps 35\n",
      "Episode 2420000, avg_s 35.000, avg_tot_r 3232.264, max_tot_r 7075.500, elapsed 33.900 s, epsilon=0.51\n",
      "Test Epoch 2420000, Total reward 5861, steps 35\n",
      "Episode 2430000, avg_s 35.000, avg_tot_r 3252.466, max_tot_r 7458.500, elapsed 35.201 s, epsilon=0.51\n",
      "Test Epoch 2430000, Total reward 6114, steps 35\n",
      "Episode 2440000, avg_s 35.000, avg_tot_r 3227.950, max_tot_r 6949.500, elapsed 33.931 s, epsilon=0.51\n",
      "Test Epoch 2440000, Total reward 6114, steps 35\n",
      "Episode 2450000, avg_s 35.000, avg_tot_r 3270.250, max_tot_r 7012.250, elapsed 35.253 s, epsilon=0.51\n",
      "Test Epoch 2450000, Total reward 6114, steps 35\n",
      "Episode 2460000, avg_s 35.000, avg_tot_r 3282.646, max_tot_r 6884.750, elapsed 35.075 s, epsilon=0.51\n",
      "Test Epoch 2460000, Total reward 6114, steps 35\n",
      "Episode 2470000, avg_s 35.000, avg_tot_r 3335.752, max_tot_r 7076.000, elapsed 34.035 s, epsilon=0.50\n",
      "Test Epoch 2470000, Total reward 5353, steps 35\n",
      "Episode 2480000, avg_s 35.000, avg_tot_r 3349.075, max_tot_r 7267.000, elapsed 32.388 s, epsilon=0.50\n",
      "Test Epoch 2480000, Total reward 5861, steps 35\n",
      "Episode 2490000, avg_s 35.000, avg_tot_r 3366.147, max_tot_r 7075.750, elapsed 31.606 s, epsilon=0.50\n",
      "Test Epoch 2490000, Total reward 6114, steps 35\n",
      "Episode 2500000, avg_s 35.000, avg_tot_r 3407.959, max_tot_r 6884.250, elapsed 33.479 s, epsilon=0.50\n",
      "Test Epoch 2500000, Total reward 5861, steps 35\n",
      "Episode 2510000, avg_s 35.000, avg_tot_r 3388.030, max_tot_r 7043.875, elapsed 34.915 s, epsilon=0.50\n",
      "Test Epoch 2510000, Total reward 5861, steps 35\n",
      "Episode 2520000, avg_s 35.000, avg_tot_r 3409.412, max_tot_r 7012.000, elapsed 33.271 s, epsilon=0.50\n",
      "Test Epoch 2520000, Total reward 5861, steps 35\n",
      "Episode 2530000, avg_s 35.000, avg_tot_r 3424.744, max_tot_r 7012.500, elapsed 31.898 s, epsilon=0.50\n",
      "Test Epoch 2530000, Total reward 6114, steps 35\n",
      "Episode 2540000, avg_s 35.000, avg_tot_r 3474.069, max_tot_r 7267.500, elapsed 32.444 s, epsilon=0.49\n",
      "Test Epoch 2540000, Total reward 5861, steps 35\n",
      "Episode 2550000, avg_s 35.000, avg_tot_r 3474.618, max_tot_r 7203.250, elapsed 33.402 s, epsilon=0.49\n",
      "Test Epoch 2550000, Total reward 6114, steps 35\n",
      "Episode 2560000, avg_s 35.000, avg_tot_r 3499.899, max_tot_r 7204.250, elapsed 33.866 s, epsilon=0.49\n",
      "Test Epoch 2560000, Total reward 6114, steps 35\n",
      "Episode 2570000, avg_s 35.000, avg_tot_r 3498.999, max_tot_r 7012.250, elapsed 32.998 s, epsilon=0.49\n",
      "Test Epoch 2570000, Total reward 6114, steps 35\n",
      "Episode 2580000, avg_s 35.000, avg_tot_r 3522.161, max_tot_r 7076.500, elapsed 32.021 s, epsilon=0.49\n",
      "Test Epoch 2580000, Total reward 6367, steps 35\n",
      "Episode 2590000, avg_s 35.000, avg_tot_r 3539.121, max_tot_r 6884.000, elapsed 32.783 s, epsilon=0.49\n",
      "Test Epoch 2590000, Total reward 6114, steps 35\n",
      "Episode 2600000, avg_s 35.000, avg_tot_r 3580.654, max_tot_r 7269.000, elapsed 33.829 s, epsilon=0.48\n",
      "Test Epoch 2600000, Total reward 6114, steps 35\n",
      "Episode 2610000, avg_s 35.000, avg_tot_r 3614.694, max_tot_r 7108.375, elapsed 33.951 s, epsilon=0.48\n",
      "Test Epoch 2610000, Total reward 6114, steps 35\n",
      "Episode 2620000, avg_s 35.000, avg_tot_r 3619.146, max_tot_r 7139.750, elapsed 31.921 s, epsilon=0.48\n",
      "Test Epoch 2620000, Total reward 6367, steps 35\n",
      "Episode 2630000, avg_s 35.000, avg_tot_r 3648.930, max_tot_r 7299.875, elapsed 32.583 s, epsilon=0.48\n",
      "Test Epoch 2630000, Total reward 5607, steps 35\n",
      "Episode 2640000, avg_s 35.000, avg_tot_r 3669.513, max_tot_r 7043.875, elapsed 34.302 s, epsilon=0.48\n",
      "Test Epoch 2640000, Total reward 5353, steps 35\n",
      "Episode 2650000, avg_s 35.000, avg_tot_r 3694.537, max_tot_r 7267.500, elapsed 34.006 s, epsilon=0.48\n",
      "Test Epoch 2650000, Total reward 6367, steps 35\n",
      "Episode 2660000, avg_s 35.000, avg_tot_r 3722.038, max_tot_r 7076.500, elapsed 31.996 s, epsilon=0.47\n",
      "Test Epoch 2660000, Total reward 6114, steps 35\n",
      "Episode 2670000, avg_s 35.000, avg_tot_r 3734.233, max_tot_r 7204.250, elapsed 31.862 s, epsilon=0.47\n",
      "Test Epoch 2670000, Total reward 6114, steps 35\n",
      "Episode 2680000, avg_s 35.000, avg_tot_r 3749.154, max_tot_r 7075.500, elapsed 32.790 s, epsilon=0.47\n",
      "Test Epoch 2680000, Total reward 6114, steps 35\n",
      "Episode 2690000, avg_s 35.000, avg_tot_r 3750.493, max_tot_r 7140.000, elapsed 34.104 s, epsilon=0.47\n",
      "Test Epoch 2690000, Total reward 5861, steps 35\n",
      "Episode 2700000, avg_s 35.000, avg_tot_r 3785.641, max_tot_r 7267.250, elapsed 32.306 s, epsilon=0.47\n",
      "Test Epoch 2700000, Total reward 6114, steps 35\n",
      "Episode 2710000, avg_s 35.000, avg_tot_r 3781.165, max_tot_r 7076.500, elapsed 32.312 s, epsilon=0.47\n",
      "Test Epoch 2710000, Total reward 6367, steps 35\n",
      "Episode 2720000, avg_s 35.000, avg_tot_r 3841.644, max_tot_r 7268.000, elapsed 32.307 s, epsilon=0.46\n",
      "Test Epoch 2720000, Total reward 6114, steps 35\n",
      "Episode 2730000, avg_s 35.000, avg_tot_r 3846.505, max_tot_r 7203.750, elapsed 33.359 s, epsilon=0.46\n",
      "Test Epoch 2730000, Total reward 6114, steps 35\n",
      "Episode 2740000, avg_s 35.000, avg_tot_r 3845.670, max_tot_r 7205.750, elapsed 32.799 s, epsilon=0.46\n",
      "Test Epoch 2740000, Total reward 6367, steps 35\n",
      "Episode 2750000, avg_s 35.000, avg_tot_r 3884.797, max_tot_r 7459.000, elapsed 32.482 s, epsilon=0.46\n",
      "Test Epoch 2750000, Total reward 6367, steps 35\n",
      "Episode 2760000, avg_s 35.000, avg_tot_r 3902.729, max_tot_r 7076.500, elapsed 31.899 s, epsilon=0.46\n",
      "Test Epoch 2760000, Total reward 6114, steps 35\n",
      "Episode 2770000, avg_s 35.000, avg_tot_r 3918.449, max_tot_r 7204.000, elapsed 32.175 s, epsilon=0.46\n",
      "Test Epoch 2770000, Total reward 5861, steps 35\n",
      "Episode 2780000, avg_s 35.000, avg_tot_r 3929.463, max_tot_r 7267.500, elapsed 34.038 s, epsilon=0.46\n",
      "Test Epoch 2780000, Total reward 6114, steps 35\n",
      "Episode 2790000, avg_s 35.000, avg_tot_r 3934.012, max_tot_r 7332.250, elapsed 32.126 s, epsilon=0.45\n",
      "Test Epoch 2790000, Total reward 6114, steps 35\n",
      "Episode 2800000, avg_s 35.000, avg_tot_r 3952.947, max_tot_r 7205.125, elapsed 31.494 s, epsilon=0.45\n",
      "Test Epoch 2800000, Total reward 6367, steps 35\n",
      "Episode 2810000, avg_s 35.000, avg_tot_r 3970.630, max_tot_r 7267.500, elapsed 31.075 s, epsilon=0.45\n",
      "Test Epoch 2810000, Total reward 6114, steps 35\n",
      "Episode 2820000, avg_s 35.000, avg_tot_r 3987.000, max_tot_r 7203.250, elapsed 32.312 s, epsilon=0.45\n",
      "Test Epoch 2820000, Total reward 5861, steps 35\n",
      "Episode 2830000, avg_s 35.000, avg_tot_r 4029.003, max_tot_r 7204.250, elapsed 34.610 s, epsilon=0.45\n",
      "Test Epoch 2830000, Total reward 5861, steps 35\n",
      "Episode 2840000, avg_s 35.000, avg_tot_r 4030.153, max_tot_r 7331.250, elapsed 35.404 s, epsilon=0.45\n",
      "Test Epoch 2840000, Total reward 5861, steps 35\n",
      "Episode 2850000, avg_s 35.000, avg_tot_r 4075.585, max_tot_r 7267.000, elapsed 34.150 s, epsilon=0.44\n",
      "Test Epoch 2850000, Total reward 5861, steps 35\n",
      "Episode 2860000, avg_s 35.000, avg_tot_r 4095.335, max_tot_r 7235.625, elapsed 34.763 s, epsilon=0.44\n",
      "Test Epoch 2860000, Total reward 6618, steps 35\n",
      "Episode 2870000, avg_s 35.000, avg_tot_r 4103.055, max_tot_r 7458.750, elapsed 34.004 s, epsilon=0.44\n",
      "Test Epoch 2870000, Total reward 5607, steps 35\n",
      "Episode 2880000, avg_s 35.000, avg_tot_r 4156.078, max_tot_r 7458.500, elapsed 31.904 s, epsilon=0.44\n",
      "Test Epoch 2880000, Total reward 6367, steps 35\n",
      "Episode 2890000, avg_s 35.000, avg_tot_r 4138.317, max_tot_r 7395.500, elapsed 31.871 s, epsilon=0.44\n",
      "Test Epoch 2890000, Total reward 6367, steps 35\n",
      "Episode 2900000, avg_s 35.000, avg_tot_r 4166.250, max_tot_r 7394.500, elapsed 32.910 s, epsilon=0.44\n",
      "Test Epoch 2900000, Total reward 6618, steps 35\n",
      "Episode 2910000, avg_s 35.000, avg_tot_r 4166.408, max_tot_r 7267.750, elapsed 35.153 s, epsilon=0.43\n",
      "Test Epoch 2910000, Total reward 6618, steps 35\n",
      "Episode 2920000, avg_s 35.000, avg_tot_r 4179.918, max_tot_r 7331.750, elapsed 35.072 s, epsilon=0.43\n",
      "Test Epoch 2920000, Total reward 6367, steps 35\n",
      "Episode 2930000, avg_s 35.000, avg_tot_r 4217.586, max_tot_r 7395.500, elapsed 34.429 s, epsilon=0.43\n",
      "Test Epoch 2930000, Total reward 6114, steps 35\n",
      "Episode 2940000, avg_s 35.000, avg_tot_r 4222.608, max_tot_r 7396.000, elapsed 34.423 s, epsilon=0.43\n",
      "Test Epoch 2940000, Total reward 6114, steps 35\n",
      "Episode 2950000, avg_s 35.000, avg_tot_r 4255.531, max_tot_r 7459.000, elapsed 32.886 s, epsilon=0.43\n",
      "Test Epoch 2950000, Total reward 6618, steps 35\n",
      "Episode 2960000, avg_s 35.000, avg_tot_r 4288.875, max_tot_r 7458.500, elapsed 32.309 s, epsilon=0.43\n",
      "Test Epoch 2960000, Total reward 6114, steps 35\n",
      "Episode 2970000, avg_s 35.000, avg_tot_r 4281.384, max_tot_r 7459.250, elapsed 32.280 s, epsilon=0.42\n",
      "Test Epoch 2970000, Total reward 6367, steps 35\n",
      "Episode 2980000, avg_s 35.000, avg_tot_r 4304.844, max_tot_r 7235.375, elapsed 31.761 s, epsilon=0.42\n",
      "Test Epoch 2980000, Total reward 6367, steps 35\n",
      "Episode 2990000, avg_s 35.000, avg_tot_r 4333.207, max_tot_r 7267.250, elapsed 32.244 s, epsilon=0.42\n",
      "Test Epoch 2990000, Total reward 6114, steps 35\n",
      "Episode 3000000, avg_s 35.000, avg_tot_r 4347.265, max_tot_r 7331.500, elapsed 32.161 s, epsilon=0.42\n",
      "Test Epoch 3000000, Total reward 6367, steps 35\n",
      "Episode 3010000, avg_s 35.000, avg_tot_r 4340.811, max_tot_r 7331.750, elapsed 33.439 s, epsilon=0.42\n",
      "Test Epoch 3010000, Total reward 6367, steps 35\n",
      "Episode 3020000, avg_s 35.000, avg_tot_r 4363.164, max_tot_r 7267.000, elapsed 32.029 s, epsilon=0.42\n",
      "Test Epoch 3020000, Total reward 6367, steps 35\n",
      "Episode 3030000, avg_s 35.000, avg_tot_r 4387.547, max_tot_r 7267.750, elapsed 32.657 s, epsilon=0.42\n",
      "Test Epoch 3030000, Total reward 6114, steps 35\n",
      "Episode 3040000, avg_s 35.000, avg_tot_r 4432.846, max_tot_r 7331.750, elapsed 32.647 s, epsilon=0.41\n",
      "Test Epoch 3040000, Total reward 6367, steps 35\n",
      "Episode 3050000, avg_s 35.000, avg_tot_r 4448.432, max_tot_r 7586.250, elapsed 32.878 s, epsilon=0.41\n",
      "Test Epoch 3050000, Total reward 6114, steps 35\n",
      "Episode 3060000, avg_s 35.000, avg_tot_r 4464.840, max_tot_r 7394.750, elapsed 33.525 s, epsilon=0.41\n",
      "Test Epoch 3060000, Total reward 6114, steps 35\n",
      "Episode 3070000, avg_s 35.000, avg_tot_r 4479.610, max_tot_r 7331.000, elapsed 33.688 s, epsilon=0.41\n",
      "Test Epoch 3070000, Total reward 6618, steps 35\n",
      "Episode 3080000, avg_s 35.000, avg_tot_r 4502.349, max_tot_r 7650.000, elapsed 33.981 s, epsilon=0.41\n",
      "Test Epoch 3080000, Total reward 6114, steps 35\n",
      "Episode 3090000, avg_s 35.000, avg_tot_r 4508.891, max_tot_r 7459.250, elapsed 33.969 s, epsilon=0.41\n",
      "Test Epoch 3090000, Total reward 6367, steps 35\n",
      "Episode 3100000, avg_s 35.000, avg_tot_r 4529.566, max_tot_r 7586.000, elapsed 35.818 s, epsilon=0.40\n",
      "Test Epoch 3100000, Total reward 6367, steps 35\n",
      "Episode 3110000, avg_s 35.000, avg_tot_r 4560.886, max_tot_r 7331.000, elapsed 34.410 s, epsilon=0.40\n",
      "Test Epoch 3110000, Total reward 5861, steps 35\n",
      "Episode 3120000, avg_s 35.000, avg_tot_r 4550.932, max_tot_r 7587.500, elapsed 32.907 s, epsilon=0.40\n",
      "Test Epoch 3120000, Total reward 6869, steps 35\n",
      "Episode 3130000, avg_s 35.000, avg_tot_r 4600.744, max_tot_r 7459.250, elapsed 32.820 s, epsilon=0.40\n",
      "Test Epoch 3130000, Total reward 5861, steps 35\n",
      "Episode 3140000, avg_s 35.000, avg_tot_r 4587.386, max_tot_r 7650.250, elapsed 33.070 s, epsilon=0.40\n",
      "Test Epoch 3140000, Total reward 6618, steps 35\n",
      "Episode 3150000, avg_s 35.000, avg_tot_r 4631.303, max_tot_r 7522.500, elapsed 32.079 s, epsilon=0.40\n",
      "Test Epoch 3150000, Total reward 6869, steps 35\n",
      "Episode 3160000, avg_s 35.000, avg_tot_r 4658.980, max_tot_r 7586.250, elapsed 32.287 s, epsilon=0.39\n",
      "Test Epoch 3160000, Total reward 6618, steps 35\n",
      "Episode 3170000, avg_s 35.000, avg_tot_r 4656.830, max_tot_r 7650.000, elapsed 32.142 s, epsilon=0.39\n",
      "Test Epoch 3170000, Total reward 6869, steps 35\n",
      "Episode 3180000, avg_s 35.000, avg_tot_r 4657.839, max_tot_r 7650.500, elapsed 32.539 s, epsilon=0.39\n",
      "Test Epoch 3180000, Total reward 6618, steps 35\n",
      "Episode 3190000, avg_s 35.000, avg_tot_r 4696.954, max_tot_r 7777.500, elapsed 32.771 s, epsilon=0.39\n",
      "Test Epoch 3190000, Total reward 6618, steps 35\n",
      "Episode 3200000, avg_s 35.000, avg_tot_r 4719.006, max_tot_r 7522.500, elapsed 31.989 s, epsilon=0.39\n",
      "Test Epoch 3200000, Total reward 6869, steps 35\n",
      "Episode 3210000, avg_s 35.000, avg_tot_r 4735.208, max_tot_r 7523.000, elapsed 32.962 s, epsilon=0.39\n",
      "Test Epoch 3210000, Total reward 5861, steps 35\n",
      "Episode 3220000, avg_s 35.000, avg_tot_r 4753.642, max_tot_r 7523.750, elapsed 31.833 s, epsilon=0.38\n",
      "Test Epoch 3220000, Total reward 6869, steps 35\n",
      "Episode 3230000, avg_s 35.000, avg_tot_r 4772.968, max_tot_r 7586.250, elapsed 32.251 s, epsilon=0.38\n",
      "Test Epoch 3230000, Total reward 6869, steps 35\n",
      "Episode 3240000, avg_s 35.000, avg_tot_r 4775.046, max_tot_r 7713.500, elapsed 32.147 s, epsilon=0.38\n",
      "Test Epoch 3240000, Total reward 6869, steps 35\n",
      "Episode 3250000, avg_s 35.000, avg_tot_r 4810.989, max_tot_r 7649.750, elapsed 32.331 s, epsilon=0.38\n",
      "Test Epoch 3250000, Total reward 6869, steps 35\n",
      "Episode 3260000, avg_s 35.000, avg_tot_r 4833.489, max_tot_r 7522.750, elapsed 32.643 s, epsilon=0.38\n",
      "Test Epoch 3260000, Total reward 6114, steps 35\n",
      "Episode 3270000, avg_s 35.000, avg_tot_r 4824.220, max_tot_r 7969.250, elapsed 33.582 s, epsilon=0.38\n",
      "Test Epoch 3270000, Total reward 6869, steps 35\n",
      "Episode 3280000, avg_s 35.000, avg_tot_r 4873.986, max_tot_r 7586.000, elapsed 31.903 s, epsilon=0.38\n",
      "Test Epoch 3280000, Total reward 6618, steps 35\n",
      "Episode 3290000, avg_s 35.000, avg_tot_r 4896.218, max_tot_r 7458.500, elapsed 32.786 s, epsilon=0.37\n",
      "Test Epoch 3290000, Total reward 6869, steps 35\n",
      "Episode 3300000, avg_s 35.000, avg_tot_r 4898.257, max_tot_r 7586.500, elapsed 34.193 s, epsilon=0.37\n",
      "Test Epoch 3300000, Total reward 6869, steps 35\n",
      "Episode 3310000, avg_s 35.000, avg_tot_r 4913.391, max_tot_r 7649.750, elapsed 32.664 s, epsilon=0.37\n",
      "Test Epoch 3310000, Total reward 6618, steps 35\n",
      "Episode 3320000, avg_s 35.000, avg_tot_r 4953.780, max_tot_r 7522.750, elapsed 32.364 s, epsilon=0.37\n",
      "Test Epoch 3320000, Total reward 6367, steps 35\n",
      "Episode 3330000, avg_s 35.000, avg_tot_r 4959.820, max_tot_r 7458.250, elapsed 33.556 s, epsilon=0.37\n",
      "Test Epoch 3330000, Total reward 6869, steps 35\n",
      "Episode 3340000, avg_s 35.000, avg_tot_r 4967.980, max_tot_r 7968.500, elapsed 35.276 s, epsilon=0.37\n",
      "Test Epoch 3340000, Total reward 6618, steps 35\n",
      "Episode 3350000, avg_s 35.000, avg_tot_r 4998.227, max_tot_r 7713.750, elapsed 34.458 s, epsilon=0.36\n",
      "Test Epoch 3350000, Total reward 7116, steps 35\n",
      "Episode 3360000, avg_s 35.000, avg_tot_r 5010.403, max_tot_r 7968.500, elapsed 34.999 s, epsilon=0.36\n",
      "Test Epoch 3360000, Total reward 7116, steps 35\n",
      "Episode 3370000, avg_s 35.000, avg_tot_r 5025.066, max_tot_r 7713.500, elapsed 35.607 s, epsilon=0.36\n",
      "Test Epoch 3370000, Total reward 7116, steps 35\n",
      "Episode 3380000, avg_s 35.000, avg_tot_r 5047.134, max_tot_r 7650.750, elapsed 33.672 s, epsilon=0.36\n",
      "Test Epoch 3380000, Total reward 7116, steps 35\n",
      "Episode 3390000, avg_s 35.000, avg_tot_r 5075.927, max_tot_r 7777.500, elapsed 31.923 s, epsilon=0.36\n",
      "Test Epoch 3390000, Total reward 7116, steps 35\n",
      "Episode 3400000, avg_s 35.000, avg_tot_r 5075.174, max_tot_r 7969.000, elapsed 32.096 s, epsilon=0.36\n",
      "Test Epoch 3400000, Total reward 6618, steps 35\n",
      "Episode 3410000, avg_s 35.000, avg_tot_r 5109.576, max_tot_r 7842.250, elapsed 32.979 s, epsilon=0.35\n",
      "Test Epoch 3410000, Total reward 6618, steps 35\n",
      "Episode 3420000, avg_s 35.000, avg_tot_r 5135.072, max_tot_r 7777.500, elapsed 32.171 s, epsilon=0.35\n",
      "Test Epoch 3420000, Total reward 6367, steps 35\n",
      "Episode 3430000, avg_s 35.000, avg_tot_r 5122.230, max_tot_r 7713.500, elapsed 33.211 s, epsilon=0.35\n",
      "Test Epoch 3430000, Total reward 7116, steps 35\n",
      "Episode 3440000, avg_s 35.000, avg_tot_r 5157.104, max_tot_r 7905.000, elapsed 32.748 s, epsilon=0.35\n",
      "Test Epoch 3440000, Total reward 6114, steps 35\n",
      "Episode 3450000, avg_s 35.000, avg_tot_r 5196.424, max_tot_r 7905.000, elapsed 35.098 s, epsilon=0.35\n",
      "Test Epoch 3450000, Total reward 7116, steps 35\n",
      "Episode 3460000, avg_s 35.000, avg_tot_r 5180.258, max_tot_r 7681.875, elapsed 31.005 s, epsilon=0.35\n",
      "Test Epoch 3460000, Total reward 7116, steps 35\n",
      "Episode 3470000, avg_s 35.000, avg_tot_r 5197.573, max_tot_r 7904.500, elapsed 32.369 s, epsilon=0.34\n",
      "Test Epoch 3470000, Total reward 6618, steps 35\n",
      "Episode 3480000, avg_s 35.000, avg_tot_r 5226.404, max_tot_r 7714.250, elapsed 29.776 s, epsilon=0.34\n",
      "Test Epoch 3480000, Total reward 6869, steps 35\n",
      "Episode 3490000, avg_s 35.000, avg_tot_r 5248.336, max_tot_r 7905.000, elapsed 29.185 s, epsilon=0.34\n",
      "Test Epoch 3490000, Total reward 6367, steps 35\n",
      "Episode 3500000, avg_s 35.000, avg_tot_r 5262.519, max_tot_r 7777.000, elapsed 29.181 s, epsilon=0.34\n",
      "Test Epoch 3500000, Total reward 7116, steps 35\n",
      "Episode 3510000, avg_s 35.000, avg_tot_r 5287.142, max_tot_r 7905.000, elapsed 29.817 s, epsilon=0.34\n",
      "Test Epoch 3510000, Total reward 6869, steps 35\n",
      "Episode 3520000, avg_s 35.000, avg_tot_r 5273.005, max_tot_r 7905.500, elapsed 29.279 s, epsilon=0.34\n",
      "Test Epoch 3520000, Total reward 7116, steps 35\n",
      "Episode 3530000, avg_s 35.000, avg_tot_r 5324.698, max_tot_r 8160.000, elapsed 29.096 s, epsilon=0.34\n",
      "Test Epoch 3530000, Total reward 7116, steps 35\n",
      "Episode 3540000, avg_s 35.000, avg_tot_r 5332.350, max_tot_r 7777.000, elapsed 29.095 s, epsilon=0.33\n",
      "Test Epoch 3540000, Total reward 6869, steps 35\n",
      "Episode 3550000, avg_s 35.000, avg_tot_r 5344.177, max_tot_r 7841.750, elapsed 30.833 s, epsilon=0.33\n",
      "Test Epoch 3550000, Total reward 7116, steps 35\n",
      "Episode 3560000, avg_s 35.000, avg_tot_r 5364.441, max_tot_r 8223.500, elapsed 37.354 s, epsilon=0.33\n",
      "Test Epoch 3560000, Total reward 7116, steps 35\n",
      "Episode 3570000, avg_s 35.000, avg_tot_r 5403.755, max_tot_r 7904.500, elapsed 36.201 s, epsilon=0.33\n",
      "Test Epoch 3570000, Total reward 7116, steps 35\n",
      "Episode 3580000, avg_s 35.000, avg_tot_r 5398.411, max_tot_r 7905.000, elapsed 36.222 s, epsilon=0.33\n",
      "Test Epoch 3580000, Total reward 7116, steps 35\n",
      "Episode 3590000, avg_s 35.000, avg_tot_r 5431.135, max_tot_r 8415.000, elapsed 38.864 s, epsilon=0.33\n",
      "Test Epoch 3590000, Total reward 6618, steps 35\n",
      "Episode 3600000, avg_s 35.000, avg_tot_r 5444.120, max_tot_r 8351.250, elapsed 36.151 s, epsilon=0.32\n",
      "Test Epoch 3600000, Total reward 6869, steps 35\n",
      "Episode 3610000, avg_s 35.000, avg_tot_r 5468.470, max_tot_r 8478.500, elapsed 34.805 s, epsilon=0.32\n",
      "Test Epoch 3610000, Total reward 7116, steps 35\n",
      "Episode 3620000, avg_s 35.000, avg_tot_r 5479.764, max_tot_r 8415.500, elapsed 34.964 s, epsilon=0.32\n",
      "Test Epoch 3620000, Total reward 7116, steps 35\n",
      "Episode 3630000, avg_s 35.000, avg_tot_r 5514.355, max_tot_r 8351.000, elapsed 35.408 s, epsilon=0.32\n",
      "Test Epoch 3630000, Total reward 7116, steps 35\n",
      "Episode 3640000, avg_s 35.000, avg_tot_r 5532.419, max_tot_r 8415.000, elapsed 34.838 s, epsilon=0.32\n",
      "Test Epoch 3640000, Total reward 7363, steps 35\n",
      "Episode 3650000, avg_s 35.000, avg_tot_r 5533.075, max_tot_r 8415.000, elapsed 35.047 s, epsilon=0.32\n",
      "Test Epoch 3650000, Total reward 7363, steps 35\n",
      "Episode 3660000, avg_s 35.000, avg_tot_r 5558.685, max_tot_r 8478.500, elapsed 35.091 s, epsilon=0.31\n",
      "Test Epoch 3660000, Total reward 7116, steps 35\n",
      "Episode 3670000, avg_s 35.000, avg_tot_r 5569.114, max_tot_r 8415.000, elapsed 34.764 s, epsilon=0.31\n",
      "Test Epoch 3670000, Total reward 6869, steps 35\n",
      "Episode 3680000, avg_s 35.000, avg_tot_r 5583.383, max_tot_r 8415.500, elapsed 34.822 s, epsilon=0.31\n",
      "Test Epoch 3680000, Total reward 7116, steps 35\n",
      "Episode 3690000, avg_s 35.000, avg_tot_r 5608.567, max_tot_r 8415.000, elapsed 34.948 s, epsilon=0.31\n",
      "Test Epoch 3690000, Total reward 7363, steps 35\n",
      "Episode 3700000, avg_s 35.000, avg_tot_r 5634.577, max_tot_r 8415.000, elapsed 35.484 s, epsilon=0.31\n",
      "Test Epoch 3700000, Total reward 7363, steps 35\n",
      "Episode 3710000, avg_s 35.000, avg_tot_r 5635.147, max_tot_r 8478.500, elapsed 35.098 s, epsilon=0.31\n",
      "Test Epoch 3710000, Total reward 7363, steps 35\n",
      "Episode 3720000, avg_s 35.000, avg_tot_r 5652.150, max_tot_r 8223.500, elapsed 35.099 s, epsilon=0.30\n",
      "Test Epoch 3720000, Total reward 7363, steps 35\n",
      "Episode 3730000, avg_s 35.000, avg_tot_r 5686.612, max_tot_r 8223.500, elapsed 36.044 s, epsilon=0.30\n",
      "Test Epoch 3730000, Total reward 7116, steps 35\n",
      "Episode 3740000, avg_s 35.000, avg_tot_r 5671.962, max_tot_r 8415.000, elapsed 34.808 s, epsilon=0.30\n",
      "Test Epoch 3740000, Total reward 7116, steps 35\n",
      "Episode 3750000, avg_s 35.000, avg_tot_r 5712.753, max_tot_r 8415.000, elapsed 35.162 s, epsilon=0.30\n",
      "Test Epoch 3750000, Total reward 6618, steps 35\n",
      "Episode 3760000, avg_s 35.000, avg_tot_r 5732.141, max_tot_r 8415.000, elapsed 35.171 s, epsilon=0.30\n",
      "Test Epoch 3760000, Total reward 6869, steps 35\n",
      "Episode 3770000, avg_s 35.000, avg_tot_r 5749.285, max_tot_r 8415.500, elapsed 35.442 s, epsilon=0.30\n",
      "Test Epoch 3770000, Total reward 7363, steps 35\n",
      "Episode 3780000, avg_s 35.000, avg_tot_r 5759.163, max_tot_r 8670.000, elapsed 35.428 s, epsilon=0.30\n",
      "Test Epoch 3780000, Total reward 6869, steps 35\n",
      "Episode 3790000, avg_s 35.000, avg_tot_r 5770.928, max_tot_r 8223.500, elapsed 34.900 s, epsilon=0.29\n",
      "Test Epoch 3790000, Total reward 7363, steps 35\n",
      "Episode 3800000, avg_s 35.000, avg_tot_r 5794.610, max_tot_r 8415.000, elapsed 35.644 s, epsilon=0.29\n",
      "Test Epoch 3800000, Total reward 6618, steps 35\n",
      "Episode 3810000, avg_s 35.000, avg_tot_r 5800.751, max_tot_r 8223.500, elapsed 36.791 s, epsilon=0.29\n",
      "Test Epoch 3810000, Total reward 7363, steps 35\n",
      "Episode 3820000, avg_s 35.000, avg_tot_r 5797.094, max_tot_r 8415.500, elapsed 35.286 s, epsilon=0.29\n",
      "Test Epoch 3820000, Total reward 7363, steps 35\n",
      "Episode 3830000, avg_s 35.000, avg_tot_r 5862.290, max_tot_r 8415.000, elapsed 41.050 s, epsilon=0.29\n",
      "Test Epoch 3830000, Total reward 6367, steps 35\n",
      "Episode 3840000, avg_s 35.000, avg_tot_r 5865.811, max_tot_r 8415.500, elapsed 30.027 s, epsilon=0.29\n",
      "Test Epoch 3840000, Total reward 7116, steps 35\n",
      "Episode 3850000, avg_s 35.000, avg_tot_r 5877.655, max_tot_r 8223.500, elapsed 31.746 s, epsilon=0.28\n",
      "Test Epoch 3850000, Total reward 6618, steps 35\n",
      "Episode 3860000, avg_s 35.000, avg_tot_r 5886.058, max_tot_r 8478.500, elapsed 34.118 s, epsilon=0.28\n",
      "Test Epoch 3860000, Total reward 7363, steps 35\n",
      "Episode 3870000, avg_s 35.000, avg_tot_r 5917.509, max_tot_r 8287.500, elapsed 34.005 s, epsilon=0.28\n",
      "Test Epoch 3870000, Total reward 7363, steps 35\n",
      "Episode 3880000, avg_s 35.000, avg_tot_r 5937.428, max_tot_r 8670.000, elapsed 108.193 s, epsilon=0.28\n",
      "Test Epoch 3880000, Total reward 6869, steps 35\n",
      "Episode 3890000, avg_s 35.000, avg_tot_r 5922.950, max_tot_r 8223.500, elapsed 77.199 s, epsilon=0.28\n",
      "Test Epoch 3890000, Total reward 6869, steps 35\n",
      "Episode 3900000, avg_s 35.000, avg_tot_r 5948.279, max_tot_r 8415.000, elapsed 85.606 s, epsilon=0.28\n",
      "Test Epoch 3900000, Total reward 6869, steps 35\n",
      "Episode 3910000, avg_s 35.000, avg_tot_r 5954.854, max_tot_r 8415.000, elapsed 60.860 s, epsilon=0.27\n",
      "Test Epoch 3910000, Total reward 6618, steps 35\n",
      "Episode 3920000, avg_s 35.000, avg_tot_r 5972.963, max_tot_r 8223.500, elapsed 52.841 s, epsilon=0.27\n",
      "Test Epoch 3920000, Total reward 7363, steps 35\n",
      "Episode 3930000, avg_s 35.000, avg_tot_r 6013.842, max_tot_r 8415.000, elapsed 41.988 s, epsilon=0.27\n",
      "Test Epoch 3930000, Total reward 5861, steps 35\n",
      "Episode 3940000, avg_s 35.000, avg_tot_r 5997.268, max_tot_r 8415.000, elapsed 33.795 s, epsilon=0.27\n",
      "Test Epoch 3940000, Total reward 7116, steps 35\n",
      "Episode 3950000, avg_s 35.000, avg_tot_r 6031.717, max_tot_r 8415.000, elapsed 33.441 s, epsilon=0.27\n",
      "Test Epoch 3950000, Total reward 7363, steps 35\n",
      "Episode 3960000, avg_s 35.000, avg_tot_r 6038.131, max_tot_r 8478.500, elapsed 34.059 s, epsilon=0.27\n",
      "Test Epoch 3960000, Total reward 7363, steps 35\n",
      "Episode 3970000, avg_s 35.000, avg_tot_r 6055.331, max_tot_r 8415.500, elapsed 38.427 s, epsilon=0.26\n",
      "Test Epoch 3970000, Total reward 7363, steps 35\n",
      "Episode 3980000, avg_s 35.000, avg_tot_r 6072.869, max_tot_r 8351.750, elapsed 35.803 s, epsilon=0.26\n",
      "Test Epoch 3980000, Total reward 7363, steps 35\n",
      "Episode 3990000, avg_s 35.000, avg_tot_r 6082.558, max_tot_r 8415.000, elapsed 33.864 s, epsilon=0.26\n",
      "Test Epoch 3990000, Total reward 7116, steps 35\n",
      "Episode 4000000, avg_s 35.000, avg_tot_r 6096.822, max_tot_r 8478.500, elapsed 35.301 s, epsilon=0.26\n",
      "Test Epoch 4000000, Total reward 6618, steps 35\n",
      "Episode 4010000, avg_s 35.000, avg_tot_r 6129.214, max_tot_r 8670.000, elapsed 38.342 s, epsilon=0.26\n",
      "Test Epoch 4010000, Total reward 7116, steps 35\n",
      "Episode 4020000, avg_s 35.000, avg_tot_r 6121.072, max_tot_r 8542.500, elapsed 35.548 s, epsilon=0.26\n",
      "Test Epoch 4020000, Total reward 6618, steps 35\n",
      "Episode 4030000, avg_s 35.000, avg_tot_r 6151.842, max_tot_r 8415.000, elapsed 32.313 s, epsilon=0.26\n",
      "Test Epoch 4030000, Total reward 6869, steps 35\n",
      "Episode 4040000, avg_s 35.000, avg_tot_r 6161.736, max_tot_r 8223.500, elapsed 30.654 s, epsilon=0.25\n",
      "Test Epoch 4040000, Total reward 6618, steps 35\n",
      "Episode 4050000, avg_s 35.000, avg_tot_r 6178.140, max_tot_r 7968.750, elapsed 31.216 s, epsilon=0.25\n",
      "Test Epoch 4050000, Total reward 6114, steps 35\n",
      "Episode 4060000, avg_s 35.000, avg_tot_r 6192.950, max_tot_r 8032.500, elapsed 32.330 s, epsilon=0.25\n",
      "Test Epoch 4060000, Total reward 7116, steps 35\n",
      "Episode 4070000, avg_s 35.000, avg_tot_r 6203.983, max_tot_r 8032.500, elapsed 33.175 s, epsilon=0.25\n",
      "Test Epoch 4070000, Total reward 7116, steps 35\n",
      "Episode 4080000, avg_s 35.000, avg_tot_r 6237.391, max_tot_r 8033.000, elapsed 32.751 s, epsilon=0.25\n",
      "Test Epoch 4080000, Total reward 7116, steps 35\n",
      "Episode 4090000, avg_s 35.000, avg_tot_r 6234.585, max_tot_r 8670.000, elapsed 30.709 s, epsilon=0.25\n",
      "Test Epoch 4090000, Total reward 7363, steps 35\n",
      "Episode 4100000, avg_s 35.000, avg_tot_r 6255.068, max_tot_r 8415.000, elapsed 30.915 s, epsilon=0.24\n",
      "Test Epoch 4100000, Total reward 7602, steps 35\n",
      "Episode 4110000, avg_s 35.000, avg_tot_r 6341.533, max_tot_r 8606.000, elapsed 31.490 s, epsilon=0.24\n",
      "Test Epoch 4110000, Total reward 7602, steps 35\n",
      "Episode 4120000, avg_s 35.000, avg_tot_r 6333.066, max_tot_r 8670.000, elapsed 31.525 s, epsilon=0.24\n",
      "Test Epoch 4120000, Total reward 7602, steps 35\n",
      "Episode 4130000, avg_s 35.000, avg_tot_r 6344.797, max_tot_r 8415.500, elapsed 29.945 s, epsilon=0.24\n",
      "Test Epoch 4130000, Total reward 7602, steps 35\n",
      "Episode 4140000, avg_s 35.000, avg_tot_r 6357.410, max_tot_r 8415.000, elapsed 30.674 s, epsilon=0.24\n",
      "Test Epoch 4140000, Total reward 7363, steps 35\n",
      "Episode 4150000, avg_s 35.000, avg_tot_r 6386.062, max_tot_r 8415.000, elapsed 31.406 s, epsilon=0.24\n",
      "Test Epoch 4150000, Total reward 7602, steps 35\n",
      "Episode 4160000, avg_s 35.000, avg_tot_r 6409.586, max_tot_r 8670.000, elapsed 32.655 s, epsilon=0.23\n",
      "Test Epoch 4160000, Total reward 7602, steps 35\n",
      "Episode 4170000, avg_s 35.000, avg_tot_r 6406.421, max_tot_r 8670.000, elapsed 31.246 s, epsilon=0.23\n",
      "Test Epoch 4170000, Total reward 7602, steps 35\n",
      "Episode 4180000, avg_s 35.000, avg_tot_r 6424.822, max_tot_r 8797.500, elapsed 30.867 s, epsilon=0.23\n",
      "Test Epoch 4180000, Total reward 6618, steps 35\n",
      "Episode 4190000, avg_s 35.000, avg_tot_r 6448.406, max_tot_r 8670.000, elapsed 31.787 s, epsilon=0.23\n",
      "Test Epoch 4190000, Total reward 7602, steps 35\n",
      "Episode 4200000, avg_s 35.000, avg_tot_r 6453.305, max_tot_r 8670.000, elapsed 31.904 s, epsilon=0.23\n",
      "Test Epoch 4200000, Total reward 7602, steps 35\n",
      "Episode 4210000, avg_s 35.000, avg_tot_r 6468.691, max_tot_r 8478.500, elapsed 32.253 s, epsilon=0.23\n",
      "Test Epoch 4210000, Total reward 7116, steps 35\n",
      "Episode 4220000, avg_s 35.000, avg_tot_r 6501.877, max_tot_r 8415.000, elapsed 30.606 s, epsilon=0.22\n",
      "Test Epoch 4220000, Total reward 6114, steps 35\n",
      "Episode 4230000, avg_s 35.000, avg_tot_r 6517.250, max_tot_r 8670.000, elapsed 29.694 s, epsilon=0.22\n",
      "Test Epoch 4230000, Total reward 7363, steps 35\n",
      "Episode 4240000, avg_s 35.000, avg_tot_r 6509.584, max_tot_r 8415.500, elapsed 30.672 s, epsilon=0.22\n",
      "Test Epoch 4240000, Total reward 7116, steps 35\n",
      "Episode 4250000, avg_s 35.000, avg_tot_r 6524.135, max_tot_r 8415.000, elapsed 32.263 s, epsilon=0.22\n",
      "Test Epoch 4250000, Total reward 7602, steps 35\n",
      "Episode 4260000, avg_s 35.000, avg_tot_r 6535.393, max_tot_r 8415.000, elapsed 31.806 s, epsilon=0.22\n",
      "Test Epoch 4260000, Total reward 7602, steps 35\n",
      "Episode 4270000, avg_s 35.000, avg_tot_r 6556.103, max_tot_r 8415.500, elapsed 30.556 s, epsilon=0.22\n",
      "Test Epoch 4270000, Total reward 7363, steps 35\n",
      "Episode 4280000, avg_s 35.000, avg_tot_r 6572.966, max_tot_r 8415.000, elapsed 29.653 s, epsilon=0.22\n",
      "Test Epoch 4280000, Total reward 7602, steps 35\n",
      "Episode 4290000, avg_s 35.000, avg_tot_r 6597.302, max_tot_r 8415.500, elapsed 31.769 s, epsilon=0.21\n",
      "Test Epoch 4290000, Total reward 7602, steps 35\n",
      "Episode 4300000, avg_s 35.000, avg_tot_r 6595.905, max_tot_r 8415.500, elapsed 31.507 s, epsilon=0.21\n",
      "Test Epoch 4300000, Total reward 7602, steps 35\n",
      "Episode 4310000, avg_s 35.000, avg_tot_r 6613.172, max_tot_r 8478.500, elapsed 32.022 s, epsilon=0.21\n",
      "Test Epoch 4310000, Total reward 7363, steps 35\n",
      "Episode 4320000, avg_s 35.000, avg_tot_r 6616.969, max_tot_r 8415.500, elapsed 31.274 s, epsilon=0.21\n",
      "Test Epoch 4320000, Total reward 7602, steps 35\n",
      "Episode 4330000, avg_s 35.000, avg_tot_r 6633.298, max_tot_r 8478.500, elapsed 29.851 s, epsilon=0.21\n",
      "Test Epoch 4330000, Total reward 7116, steps 35\n",
      "Episode 4340000, avg_s 35.000, avg_tot_r 6649.296, max_tot_r 8415.500, elapsed 29.782 s, epsilon=0.21\n",
      "Test Epoch 4340000, Total reward 7602, steps 35\n",
      "Episode 4350000, avg_s 35.000, avg_tot_r 6651.484, max_tot_r 8478.500, elapsed 31.886 s, epsilon=0.20\n",
      "Test Epoch 4350000, Total reward 7602, steps 35\n",
      "Episode 4360000, avg_s 35.000, avg_tot_r 6662.264, max_tot_r 8415.500, elapsed 31.924 s, epsilon=0.20\n",
      "Test Epoch 4360000, Total reward 7116, steps 35\n",
      "Episode 4370000, avg_s 35.000, avg_tot_r 6701.371, max_tot_r 8415.000, elapsed 31.410 s, epsilon=0.20\n",
      "Test Epoch 4370000, Total reward 7602, steps 35\n",
      "Episode 4380000, avg_s 35.000, avg_tot_r 6700.516, max_tot_r 8415.000, elapsed 29.909 s, epsilon=0.20\n",
      "Test Epoch 4380000, Total reward 7602, steps 35\n",
      "Episode 4390000, avg_s 35.000, avg_tot_r 6694.454, max_tot_r 8415.500, elapsed 31.056 s, epsilon=0.20\n",
      "Test Epoch 4390000, Total reward 7602, steps 35\n",
      "Episode 4400000, avg_s 35.000, avg_tot_r 6723.230, max_tot_r 8670.000, elapsed 31.415 s, epsilon=0.20\n",
      "Test Epoch 4400000, Total reward 7116, steps 35\n",
      "Episode 4410000, avg_s 35.000, avg_tot_r 6747.634, max_tot_r 8415.500, elapsed 31.606 s, epsilon=0.19\n",
      "Test Epoch 4410000, Total reward 7602, steps 35\n",
      "Episode 4420000, avg_s 35.000, avg_tot_r 6742.620, max_tot_r 8415.000, elapsed 30.280 s, epsilon=0.19\n",
      "Test Epoch 4420000, Total reward 7602, steps 35\n",
      "Episode 4430000, avg_s 35.000, avg_tot_r 6737.609, max_tot_r 8478.500, elapsed 30.198 s, epsilon=0.19\n",
      "Test Epoch 4430000, Total reward 7116, steps 35\n",
      "Episode 4440000, avg_s 35.000, avg_tot_r 6770.907, max_tot_r 8415.000, elapsed 31.090 s, epsilon=0.19\n",
      "Test Epoch 4440000, Total reward 7363, steps 35\n",
      "Episode 4450000, avg_s 35.000, avg_tot_r 6781.333, max_tot_r 8478.500, elapsed 31.337 s, epsilon=0.19\n",
      "Test Epoch 4450000, Total reward 7602, steps 35\n",
      "Episode 4460000, avg_s 35.000, avg_tot_r 6774.255, max_tot_r 8415.000, elapsed 29.961 s, epsilon=0.19\n",
      "Test Epoch 4460000, Total reward 6114, steps 35\n",
      "Episode 4470000, avg_s 35.000, avg_tot_r 6792.447, max_tot_r 8415.000, elapsed 30.594 s, epsilon=0.18\n",
      "Test Epoch 4470000, Total reward 7363, steps 35\n",
      "Episode 4480000, avg_s 35.000, avg_tot_r 6810.261, max_tot_r 8925.000, elapsed 30.212 s, epsilon=0.18\n",
      "Test Epoch 4480000, Total reward 7363, steps 35\n",
      "Episode 4490000, avg_s 35.000, avg_tot_r 6829.565, max_tot_r 8478.500, elapsed 30.744 s, epsilon=0.18\n",
      "Test Epoch 4490000, Total reward 6869, steps 35\n",
      "Episode 4500000, avg_s 35.000, avg_tot_r 6829.260, max_tot_r 8670.000, elapsed 29.997 s, epsilon=0.18\n",
      "Test Epoch 4500000, Total reward 7602, steps 35\n",
      "Episode 4510000, avg_s 35.000, avg_tot_r 6859.571, max_tot_r 8415.500, elapsed 29.918 s, epsilon=0.18\n",
      "Test Epoch 4510000, Total reward 7602, steps 35\n",
      "Episode 4520000, avg_s 35.000, avg_tot_r 6866.513, max_tot_r 8415.500, elapsed 30.006 s, epsilon=0.18\n",
      "Test Epoch 4520000, Total reward 7116, steps 35\n",
      "Episode 4530000, avg_s 35.000, avg_tot_r 7040.925, max_tot_r 8797.500, elapsed 29.913 s, epsilon=0.18\n",
      "Test Epoch 4530000, Total reward 8288, steps 35\n",
      "Episode 4540000, avg_s 35.000, avg_tot_r 7103.617, max_tot_r 8925.000, elapsed 29.758 s, epsilon=0.17\n",
      "Test Epoch 4540000, Total reward 8288, steps 35\n",
      "Episode 4550000, avg_s 35.000, avg_tot_r 7105.080, max_tot_r 8797.500, elapsed 30.224 s, epsilon=0.17\n",
      "Test Epoch 4550000, Total reward 8288, steps 35\n",
      "Episode 4560000, avg_s 35.000, avg_tot_r 7149.463, max_tot_r 8797.500, elapsed 29.693 s, epsilon=0.17\n",
      "Test Epoch 4560000, Total reward 8288, steps 35\n",
      "Episode 4570000, avg_s 35.000, avg_tot_r 7135.556, max_tot_r 8797.500, elapsed 29.988 s, epsilon=0.17\n",
      "Test Epoch 4570000, Total reward 8288, steps 35\n",
      "Episode 4580000, avg_s 35.000, avg_tot_r 7147.958, max_tot_r 8797.500, elapsed 30.524 s, epsilon=0.17\n",
      "Test Epoch 4580000, Total reward 8064, steps 35\n",
      "Episode 4590000, avg_s 35.000, avg_tot_r 7164.553, max_tot_r 8797.500, elapsed 30.853 s, epsilon=0.17\n",
      "Test Epoch 4590000, Total reward 8288, steps 35\n",
      "Episode 4600000, avg_s 35.000, avg_tot_r 7198.913, max_tot_r 8797.500, elapsed 30.113 s, epsilon=0.16\n",
      "Test Epoch 4600000, Total reward 8288, steps 35\n",
      "Episode 4610000, avg_s 35.000, avg_tot_r 7220.160, max_tot_r 8797.500, elapsed 31.513 s, epsilon=0.16\n",
      "Test Epoch 4610000, Total reward 8288, steps 35\n",
      "Episode 4620000, avg_s 35.000, avg_tot_r 7250.444, max_tot_r 8797.500, elapsed 29.985 s, epsilon=0.16\n",
      "Test Epoch 4620000, Total reward 8288, steps 35\n",
      "Episode 4630000, avg_s 35.000, avg_tot_r 7223.642, max_tot_r 8797.500, elapsed 30.945 s, epsilon=0.16\n",
      "Test Epoch 4630000, Total reward 7841, steps 35\n",
      "Episode 4640000, avg_s 35.000, avg_tot_r 7263.690, max_tot_r 8797.500, elapsed 30.299 s, epsilon=0.16\n",
      "Test Epoch 4640000, Total reward 8288, steps 35\n",
      "Episode 4650000, avg_s 35.000, avg_tot_r 7261.517, max_tot_r 8797.500, elapsed 30.656 s, epsilon=0.16\n",
      "Test Epoch 4650000, Total reward 8288, steps 35\n",
      "Episode 4660000, avg_s 35.000, avg_tot_r 7283.205, max_tot_r 8797.500, elapsed 31.034 s, epsilon=0.15\n",
      "Test Epoch 4660000, Total reward 8288, steps 35\n",
      "Episode 4670000, avg_s 35.000, avg_tot_r 7311.197, max_tot_r 8925.000, elapsed 35.277 s, epsilon=0.15\n",
      "Test Epoch 4670000, Total reward 7841, steps 35\n",
      "Episode 4680000, avg_s 35.000, avg_tot_r 7308.735, max_tot_r 8797.500, elapsed 30.784 s, epsilon=0.15\n",
      "Test Epoch 4680000, Total reward 8288, steps 35\n",
      "Episode 4690000, avg_s 35.000, avg_tot_r 7325.427, max_tot_r 8797.500, elapsed 32.909 s, epsilon=0.15\n",
      "Test Epoch 4690000, Total reward 8288, steps 35\n",
      "Episode 4700000, avg_s 35.000, avg_tot_r 7359.131, max_tot_r 8797.500, elapsed 31.149 s, epsilon=0.15\n",
      "Test Epoch 4700000, Total reward 8064, steps 35\n",
      "Episode 4710000, avg_s 35.000, avg_tot_r 7368.107, max_tot_r 8797.500, elapsed 30.253 s, epsilon=0.15\n",
      "Test Epoch 4710000, Total reward 8288, steps 35\n",
      "Episode 4720000, avg_s 35.000, avg_tot_r 7368.982, max_tot_r 8797.500, elapsed 30.161 s, epsilon=0.14\n",
      "Test Epoch 4720000, Total reward 8288, steps 35\n",
      "Episode 4730000, avg_s 35.000, avg_tot_r 7392.792, max_tot_r 8797.500, elapsed 31.202 s, epsilon=0.14\n",
      "Test Epoch 4730000, Total reward 8064, steps 35\n",
      "Episode 4740000, avg_s 35.000, avg_tot_r 7400.424, max_tot_r 8797.500, elapsed 30.426 s, epsilon=0.14\n",
      "Test Epoch 4740000, Total reward 8064, steps 35\n",
      "Episode 4750000, avg_s 35.000, avg_tot_r 7404.825, max_tot_r 8797.500, elapsed 30.023 s, epsilon=0.14\n",
      "Test Epoch 4750000, Total reward 8064, steps 35\n",
      "Episode 4760000, avg_s 35.000, avg_tot_r 7440.637, max_tot_r 8797.500, elapsed 30.886 s, epsilon=0.14\n",
      "Test Epoch 4760000, Total reward 8288, steps 35\n",
      "Episode 4770000, avg_s 35.000, avg_tot_r 7457.673, max_tot_r 8797.500, elapsed 31.369 s, epsilon=0.14\n",
      "Test Epoch 4770000, Total reward 7841, steps 35\n",
      "Episode 4780000, avg_s 35.000, avg_tot_r 7456.928, max_tot_r 8797.500, elapsed 30.934 s, epsilon=0.14\n",
      "Test Epoch 4780000, Total reward 8288, steps 35\n",
      "Episode 4790000, avg_s 35.000, avg_tot_r 7466.872, max_tot_r 8797.500, elapsed 30.277 s, epsilon=0.13\n",
      "Test Epoch 4790000, Total reward 7602, steps 35\n",
      "Episode 4800000, avg_s 35.000, avg_tot_r 7486.500, max_tot_r 8925.000, elapsed 30.036 s, epsilon=0.13\n",
      "Test Epoch 4800000, Total reward 8288, steps 35\n",
      "Episode 4810000, avg_s 35.000, avg_tot_r 7499.222, max_tot_r 8797.500, elapsed 31.006 s, epsilon=0.13\n",
      "Test Epoch 4810000, Total reward 8288, steps 35\n",
      "Episode 4820000, avg_s 35.000, avg_tot_r 7505.540, max_tot_r 8797.500, elapsed 31.016 s, epsilon=0.13\n",
      "Test Epoch 4820000, Total reward 8064, steps 35\n",
      "Episode 4830000, avg_s 35.000, avg_tot_r 7528.080, max_tot_r 8797.500, elapsed 30.012 s, epsilon=0.13\n",
      "Test Epoch 4830000, Total reward 8064, steps 35\n",
      "Episode 4840000, avg_s 35.000, avg_tot_r 7548.366, max_tot_r 8797.500, elapsed 30.635 s, epsilon=0.13\n",
      "Test Epoch 4840000, Total reward 8288, steps 35\n",
      "Episode 4850000, avg_s 35.000, avg_tot_r 7572.519, max_tot_r 8797.500, elapsed 32.734 s, epsilon=0.12\n",
      "Test Epoch 4850000, Total reward 8288, steps 35\n",
      "Episode 4860000, avg_s 35.000, avg_tot_r 7566.660, max_tot_r 8797.500, elapsed 32.508 s, epsilon=0.12\n",
      "Test Epoch 4860000, Total reward 7841, steps 35\n",
      "Episode 4870000, avg_s 35.000, avg_tot_r 7580.531, max_tot_r 8797.500, elapsed 30.116 s, epsilon=0.12\n",
      "Test Epoch 4870000, Total reward 8288, steps 35\n",
      "Episode 4880000, avg_s 35.000, avg_tot_r 7592.238, max_tot_r 8925.000, elapsed 30.821 s, epsilon=0.12\n",
      "Test Epoch 4880000, Total reward 8288, steps 35\n",
      "Episode 4890000, avg_s 35.000, avg_tot_r 7593.072, max_tot_r 8797.500, elapsed 31.185 s, epsilon=0.12\n",
      "Test Epoch 4890000, Total reward 8064, steps 35\n",
      "Episode 4900000, avg_s 35.000, avg_tot_r 7612.455, max_tot_r 8797.500, elapsed 32.439 s, epsilon=0.12\n",
      "Test Epoch 4900000, Total reward 8288, steps 35\n",
      "Episode 4910000, avg_s 35.000, avg_tot_r 7639.040, max_tot_r 8797.500, elapsed 30.670 s, epsilon=0.11\n",
      "Test Epoch 4910000, Total reward 8288, steps 35\n",
      "Episode 4920000, avg_s 35.000, avg_tot_r 7636.388, max_tot_r 8925.000, elapsed 30.611 s, epsilon=0.11\n",
      "Test Epoch 4920000, Total reward 8288, steps 35\n",
      "Episode 4930000, avg_s 35.000, avg_tot_r 7631.735, max_tot_r 8797.500, elapsed 30.783 s, epsilon=0.11\n",
      "Test Epoch 4930000, Total reward 8064, steps 35\n",
      "Episode 4940000, avg_s 35.000, avg_tot_r 7665.491, max_tot_r 8925.000, elapsed 32.987 s, epsilon=0.11\n",
      "Test Epoch 4940000, Total reward 8288, steps 35\n",
      "Episode 4950000, avg_s 35.000, avg_tot_r 7674.675, max_tot_r 8925.000, elapsed 34.570 s, epsilon=0.11\n",
      "Test Epoch 4950000, Total reward 8064, steps 35\n",
      "Episode 4960000, avg_s 35.000, avg_tot_r 7663.900, max_tot_r 8797.500, elapsed 30.255 s, epsilon=0.11\n",
      "Test Epoch 4960000, Total reward 8288, steps 35\n",
      "Episode 4970000, avg_s 35.000, avg_tot_r 7705.003, max_tot_r 8797.500, elapsed 30.975 s, epsilon=0.10\n",
      "Test Epoch 4970000, Total reward 8288, steps 35\n",
      "Episode 4980000, avg_s 35.000, avg_tot_r 7705.766, max_tot_r 8925.000, elapsed 30.605 s, epsilon=0.10\n",
      "Test Epoch 4980000, Total reward 8064, steps 35\n",
      "Episode 4990000, avg_s 35.000, avg_tot_r 7701.603, max_tot_r 8797.500, elapsed 30.861 s, epsilon=0.10\n",
      "Test Epoch 4990000, Total reward 8288, steps 35\n",
      "Episode 5000000, avg_s 35.000, avg_tot_r 7735.789, max_tot_r 8925.000, elapsed 30.802 s, epsilon=0.10\n",
      "Test Epoch 5000000, Total reward 8288, steps 35\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print_interval = int(eposides/(eposides / save_interval))\n",
    "avg_s = 0\n",
    "avg_tot_r = 0\n",
    "max_to_r = 0\n",
    "start_timestamp = time.time()\n",
    "for epoch in range(1, eposides+1):\n",
    "    epsilon = (eposides - epoch) * (max_epsilon - min_epsilon) / eposides + min_epsilon\n",
    "    env.reset()\n",
    "    done = False\n",
    "    state = env.init_state\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        # epsilon-greedy\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample() # Explore\n",
    "        else:\n",
    "            action = np.argmax(q_table[state,:]) # Exploit\n",
    "\n",
    "        # Move one step\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update Q table\n",
    "        q_table[state, action] = q_table[state, action] + alpha*(reward + gamma*np.max(q_table[next_state, :]) - q_table[state, action])\n",
    "        state = next_state\n",
    "\n",
    "        # Update statistics\n",
    "        steps = steps + 1\n",
    "        total_reward = total_reward + reward\n",
    "    avg_s += steps / print_interval\n",
    "    avg_tot_r += total_reward / print_interval\n",
    "    if total_reward > max_to_r:\n",
    "        max_to_r = total_reward\n",
    "    if(epoch%print_interval) == 0:\n",
    "        end_timestamp = time.time()\n",
    "        print(\"Episode {}, avg_s {:.3f}, avg_tot_r {:.3f}, max_tot_r {:.3f}, elapsed {:.3f} s, epsilon={:.2f}\".format(epoch, avg_s, avg_tot_r, max_to_r, end_timestamp-start_timestamp, epsilon))\n",
    "        avg_s = 0\n",
    "        avg_tot_r = 0\n",
    "        max_to_r = 0\n",
    "        start_timestamp = end_timestamp\n",
    "    if epoch == 1:\n",
    "        save_q_table(epoch)\n",
    "        run_test(epoch)\n",
    "    if(epoch%save_interval) == 0:\n",
    "        save_q_table(epoch)\n",
    "        run_test(epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       ...,\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table # Q table after learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average results of 1000 episodes are steps 0.035, reward 6.884\n"
     ]
    }
   ],
   "source": [
    "# Testing: Calculating the average reward of 1000 eposides\n",
    "test_episodes = 1000 # DON'T CHANGE THIS VALUE\n",
    "test_steps = 0\n",
    "test_total_reward = 0\n",
    "for i in range(test_episodes):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    test_state = env.init_state\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[test_state,:])\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        test_state = next_state\n",
    "        test_steps = test_steps + 1\n",
    "        test_total_reward = test_total_reward + reward\n",
    "\n",
    "\n",
    "print(\"The average results of {} episodes are steps {}, reward {}\".format(test_episodes, steps/test_episodes, total_reward/test_episodes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "total_avg_reward = total_reward/test_episodes\n",
    "# Print results in CSV format and upload to Kaggle\n",
    "if not os.path.exists(outputDir):\n",
    "    os.mkdir(outputDir)\n",
    "with open(outputDir+'%s' %filename, 'w') as f:\n",
    "    f.write('Id,Predicted\\n')\n",
    "    f.write('FrozenLake8x8_public,{}\\n'.format(total_avg_reward))\n",
    "    f.write('FrozenLake8x8_private,{}\\n'.format(total_avg_reward))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1af0e35e",
   "language": "python",
   "display_name": "PyCharm (1082_Deep_Reinforcement_Learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}