{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from convert import images_to_video\n",
    "from convert import state_list_to_image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% import\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_filepath = '../image/map.png'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyAction:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def sample(self):\n",
    "        return random.randint(0, self.n - 1)\n",
    "\n",
    "\n",
    "class MyObservation:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "\n",
    "class MyEnv:\n",
    "    def __init__(self, map):\n",
    "        # 上下左右\n",
    "        self.action_space = MyAction(4)\n",
    "        self.map = map\n",
    "        # [0, 1, 2, ..., 49]\n",
    "        # [50, 51, 52, ..., 99]\n",
    "        self.observation_space = MyObservation(map.shape[0]*map.shape[1])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.current_state = [22, 36]\n",
    "        self.init_state = self.current_state[0] * 50 + self.current_state[1]\n",
    "        self.reward_table = np.zeros(self.map.shape)\n",
    "        for i in range(map.shape[0]):\n",
    "            for j in range(map.shape[1]):\n",
    "                self.reward_table[i,j] = self.map[i,j]\n",
    "        for i in range(map.shape[0]):\n",
    "            for j in range(map.shape[1]):\n",
    "                if self.reward_table[i, j] != 255:\n",
    "                    self.reward_table[i, j] = -64\n",
    "                    continue\n",
    "                if (i < 22) or (i > 32):\n",
    "                    self.reward_table[i,j] = 128\n",
    "                elif j < 26:\n",
    "                    self.reward_table[i,j] = 128\n",
    "        self.reward_table[self.current_state[0], self.current_state[1]] = 0\n",
    "        self.current_reward = 0\n",
    "        self.done = False\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        if action == 0: # 上\n",
    "            self.current_state[0] -= 1\n",
    "        if action == 1: # 下\n",
    "            self.current_state[0] += 1\n",
    "        if action == 2: # 左\n",
    "            self.current_state[1] -= 1\n",
    "        if action == 3: # 右\n",
    "            self.current_state[1] += 1\n",
    "        if self.current_state[0] < 0:\n",
    "            self.current_state[0] = 0\n",
    "            self.done = True\n",
    "        if self.current_state[0] >= map.shape[0]:\n",
    "            self.current_state[0] = map.shape[0]-1\n",
    "            self.done = True\n",
    "        if self.current_state[1] < 0:\n",
    "            self.current_state[1] = 0\n",
    "            self.done = True\n",
    "        if self.current_state[1] >= map.shape[1]:\n",
    "            self.current_state[1] = map.shape[1]-1\n",
    "            self.done = True\n",
    "        self.current_reward = self.reward_table[self.current_state[0], self.current_state[1]]\n",
    "\n",
    "        if self.reward_table[self.current_state[0], self.current_state[1]] > 1:\n",
    "            self.reward_table[self.current_state[0], self.current_state[1]] /= 2\n",
    "        if self.current_step > 34:\n",
    "            self.done = True\n",
    "        next_state = self.current_state[0] * 50 + self.current_state[1]\n",
    "        reward = self.current_reward\n",
    "        done = self.done\n",
    "        info = None\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "\n",
    "map = 255 - np.array(Image.open(map_filepath).convert('L'))\n",
    "env = MyEnv(map)\n",
    "print(map[13, 26])\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actions = env.action_space.n\n",
    "states = env.observation_space.n\n",
    "eposides = 5000000\n",
    "save_interval = 10000\n",
    "epsilon = 0.2\n",
    "gamma = 0.9\n",
    "alpha = 0.01\n",
    "filename = 'rewards_%s_%s_%s_%s.csv' %(eposides, epsilon, gamma, alpha)\n",
    "outputDir = '../output/'\n",
    "\n",
    "\n",
    "\n",
    "# Create Q table with all rewards = 0\n",
    "q_table = np.zeros((states, actions))\n",
    "#q_table = np.load('q_table_20200629_20')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_q_table(epoch):\n",
    "    np.save(outputDir+'q_table_{}'.format(epoch), q_table)\n",
    "\n",
    "def run_test(epoch):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    test_state = env.init_state\n",
    "    state_list = []\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state_list.append(test_state)\n",
    "        action = np.argmax(q_table[test_state,:])\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        test_state = next_state\n",
    "        steps = steps + 1\n",
    "        total_reward = total_reward + reward\n",
    "    with open(outputDir+'state_list_{}_{:.0f}_{}.csv'.format(epoch, total_reward, steps), 'w') as output_state_list:\n",
    "        output_csv = csv.writer(output_state_list)\n",
    "        output_csv.writerow(state_list)\n",
    "    state_list_to_image.state_list_to_image(epoch, total_reward, steps, map_filepath, '../output')\n",
    "    images_to_video.images_to_video(epoch, total_reward, steps, 10, (640, 640), '../output')\n",
    "    print('Test Epoch {}, Total reward {:.0f}, steps {}'.format(epoch, total_reward, steps))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "print_interval = int(eposides/100)\n",
    "avg_s = 0\n",
    "avg_tot_r = 0\n",
    "max_to_r = 0\n",
    "for epoch in range(1, eposides+1):\n",
    "    start_timestamp = time.time()\n",
    "    env.reset()\n",
    "    done = False\n",
    "    state = env.init_state\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        # epsilon-greedy\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample() # Explore\n",
    "        else:\n",
    "            action = np.argmax(q_table[state,:]) # Exploit\n",
    "\n",
    "        # Move one step\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update Q table\n",
    "        q_table[state, action] = q_table[state, action] + alpha*(reward + gamma*np.max(q_table[next_state, :]) - q_table[state, action])\n",
    "        state = next_state\n",
    "\n",
    "        # Update statistics\n",
    "        steps = steps + 1\n",
    "        total_reward = total_reward + reward\n",
    "    avg_s += steps / print_interval\n",
    "    avg_tot_r += total_reward / print_interval\n",
    "    if total_reward > max_to_r:\n",
    "        max_to_r = total_reward\n",
    "    if(epoch%print_interval) == 0:\n",
    "        end_timestamp = time.time()\n",
    "        print(\"Episode {}, avg_s {:.3f}, avg_tot_r {:.3f}, max_tot_r {:.3f}, elapsed {:.3f} s\".format(epoch, avg_s, avg_tot_r, max_to_r, end_timestamp-start_timestamp))\n",
    "        avg_s = 0\n",
    "        avg_tot_r = 0\n",
    "        max_to_r = 0\n",
    "    if epoch == 1:\n",
    "        save_q_table(epoch)\n",
    "        run_test(epoch)\n",
    "    if(epoch%save_interval) == 0:\n",
    "        save_q_table(epoch)\n",
    "        run_test(epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q_table # Q table after learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing: Calculating the average reward of 1000 eposides\n",
    "test_episodes = 1000 # DON'T CHANGE THIS VALUE\n",
    "test_steps = 0\n",
    "test_total_reward = 0\n",
    "for i in range(test_episodes):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    test_state = env.init_state\n",
    "    state_list = []\n",
    "    while not done:\n",
    "        state_list.append(test_state)\n",
    "        action = np.argmax(q_table[test_state,:])\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        test_state = next_state\n",
    "        test_steps = test_steps + 1\n",
    "        test_total_reward = test_total_reward + reward\n",
    "\n",
    "\n",
    "print(\"The average results of {} episodes are steps {}, reward {}\".format(test_episodes, steps/test_episodes, total_reward/test_episodes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_avg_reward = total_reward/test_episodes\n",
    "# Print results in CSV format and upload to Kaggle\n",
    "if not os.path.exists(outputDir):\n",
    "    os.mkdir(outputDir)\n",
    "with open(outputDir+'%s' %filename, 'w') as f:\n",
    "    f.write('Id,Predicted\\n')\n",
    "    f.write('FrozenLake8x8_public,{}\\n'.format(total_avg_reward))\n",
    "    f.write('FrozenLake8x8_private,{}\\n'.format(total_avg_reward))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1af0e35e",
   "language": "python",
   "display_name": "PyCharm (1082_Deep_Reinforcement_Learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}